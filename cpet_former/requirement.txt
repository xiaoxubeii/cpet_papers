论文大纲：基于Transformer的自动化心肺运动试验（CPET）分析框架

目标期刊（示例）： The Lancet Digital Health, Nature Medicine, JAMA Internal Medicine, European Heart Journal

论文标题（示例）：

A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from Cardiopulmonary Exercise Tests: A Diagnostic Accuracy and Reader Study

(一个用于心肺运动试验无氧阈自动评估的多中心、可泛化的深度学习框架：一项诊断准确性与读者研究)

Development and Validation of an AI Model for Anaerobic Threshold Assessment: A Large-Scale, Multi-Center Study and Head-to-Head Comparison with Clinicians

(用于无氧阈评估的AI模型开发与验证：一项大规模多中心研究及与临床医生的头对头比较)

摘要 (Abstract)

背景 (Background): 心肺运动试验 (CPET) 中的无氧阈 (AT) 是关键预后指标，但其人工判读耗时、依赖经验，且存在显著的观察者间变异性 (inter-observer variability)。本研究旨在开发并严格验证一个自动化、可泛化的 AI 模型，以实现客观、一致的 AT 评估。

方法 (Methods): 本研究基于三个中心（中山、山西、徐汇）、两种设备（Ganshorn, Cosmed）共计 12,000 例 CPET 测试，构建了一个大规模标准化数据集。我们首先建立了“专家共识金标准” (Expert Consensus Ground Truth) 用于模型训练。我们开发了一个基于 Transformer 的框架 (CPET-former)，并使用域泛化技术 (GroupDRO) 提升其在未知中心的性能。我们通过严格的“留一中心交叉验证” (LOCO) 评估模型泛化性。最后，我们进行了一项盲法读者研究 (Reader Study)，邀请了 [例如：12] 名不同年资的临床医生，将 AI 模型的表现与人类专家进行头对头比较。

结果 (Findings):

模型性能: 我们的 AI 框架在内部交叉验证中表现出色 (MAE: [X])，且显著优于传统机器学习模型 (MAE: [Y], p < 0.001)。

泛化性 (LOCO): 在 LOCO 测试中，域泛化模型 (cpet_former_v1) 在“未知中心”的性能 (MAE: [X]) 显著高于基线模型 (MAE: [Y], p < 0.01)，证明了其强大的泛化能力。

读者研究 (关键): AI 模型的准确性 (MAE: [X]) 与高级专家相当 (MAE: [Y], p = n.s.)，并显著优于初级和中级医生 (MAE: [Z], p < 0.001)。更重要的是，人类判读者之间存在中度一致性 (ICC = [例如 0.78])，而 AI 模型表现出完美的一致性 (ICC = 1.0)。

次要分析: 自监督模型 (cpet_former_v2) 仅需 10% 的标注数据即可达到全量数据 95% 的性能。

结论 (Interpretation): 我们开发并验证了一个可泛化的 AI 框架，它能提供准确、客观且高度一致的 AT 评估。该模型在真实世界多中心环境（包括未知中心）中表现稳健，其性能媲美人类高级专家，有望标准化 CPET 分析流程并减少临床工作负担。

1. 引言 (Introduction)

临床背景: CPET 及其核心指标（如 $\text{VO}_2$ at AT）在心衰、术前评估、康复等领域的临床价值和预后意义。

临床痛点:

主观性 & 变异性: 强调 V-slope 等传统判读方法依赖人工，不同判读者（甚至同一判读者在不同时间）的“观察者间”和“观察者内”变异性高，导致临床决策不一致。

成本高: 人工判读耗时耗力，需要经验丰富的专家，限制了 CPET 的广泛应用。

现有解决方案及不足: 简述传统自动化方法（如最小二乘法）的局限性。提及现有 AI 研究大多局限于单中心、小规模数据，且缺乏在未知中心的泛化性验证，更鲜有与人类专家进行严格的头对头比较。

本研究的切入点与目标:

切入点: 临床急需一个客观、准确、且能在多中心（包括新中心）稳健运行的自动化 AT 评估工具。

我们的贡献:

构建了首个大规模、多中心、多设备的标准化 CPET 数据集 (CPET-12k)。

开发了一个基于 Transformer 的 AI 框架 (cpet_former)。

系统性地验证了其域泛化能力 (LOCO) 和少样本学习能力 (SSL)。

通过一项严格的读者研究，首次将 AI 与多层次临床医生进行头对头比较。

研究假说: AI 模型的准确性和一致性非劣于（甚至优于）人类专家。

2. 方法 (Methods)

研究设计与伦理:

一项多中心、回顾性的诊断准确性研究，并包含一项前瞻性（模拟）的读者研究。

获得 [X, Y, Z] 中心伦理委员会 (IRB) 批准，豁免知情同意。

数据收集与标准化 (CPET-12k 数据集):
- 标准定义：使用 CPET 数据标准 v1.4（cpet.yaml），以及厂商映射（cosmed.yaml, ganshorn.yaml），路径：/root/autodl-tmp/vox_cpet/cpetformat/。
- 提取（采集→标准化落盘）：`vox_cpet/cmd/cpetx-data` 的 `extract` 子命令批量遍历中心文件夹并调用对应抽取器（`vox_cpet/extractors`）。输出为每中心一个 HDF5（cpet_data_source_<center>.h5），结构为 per-examination 的 {subject, examination, calibration, summary, timeseries}。去重规则：以 (Subject_ID, Examination_Date, summary 指标摘要) 作为签名，保留首个检查；元数据记录机构信息和 schema 版本；产生日志。
- 源数据文件（原始、仅字段/单位标准化，无清洗处理）：
  - /home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_shanxi.h5
  - /home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_zhongshan.h5
  - /home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_xuhui.h5
- 清洗（特征构建）：`vox_cpet/dataset/cpet_processor.py` 将 per-examination 合并为中心级 DataFrame，并执行：
  1) 时间聚合（当原始采样频率高于配置间隔时，默认秒级），稳健均值；
  2) 线性插值 + 首/尾填充；
  3) 过滤器（可选）：运动阶段前 N 分钟、阶段筛选、时间窗口、数值范围（HR/VO2 等）；
  4) 目标列完整性：删除缺失非 AT 目标的检查；允许缺失 Time_at_AT（右删失，若仅作辅助监督）。
 - 处理后数据集（分析就绪）：/home/cheng/workspace/cpetx_workspace/cpet_former/artifacts/dataset/cpet_dataset.h5。
   - 处理内容：10s 聚合、插值、标准化、特征/目标值提取（VO2_kg_at_AT, HR_at_AT, Time_at_AT 等）。
 - 数据集生成与切分：`cpetx-data generate` 混合多个中心并生成 HDF5 数据集，支持：
  1) standard：按检查随机切分 train/val/test；
  2) explicit split：显式指定训练/验证中心与测试中心；
  3) LOCO：逐中心留出，输出每折一个文件夹。标准化：对指定列（standardization_names）在训练集拟合 StandardScaler，并将参数应用到 val/test；均值/方差与列名写入 HDF5 元数据，便于复原与审计。
- 采样：`cpetx-data sample` 对既有 HDF5 数据集按 split 抽取（可选按 center/device 分组等），生成 *_small 版本，便于快速迭代。
- 目录规范：/root/autodl-tmp/cpet_workspace/artifacts/cpet_dataset 下统一管理：
  - cpet_dataset：全量混合数据集
  - *_small：10% 抽样集
  - *_ssl：自监督预训练集
  - *_explicit_split：train/val 为三中心，test 为外部 punan 数据集
  - *_loco：三中心轮流作为留出测试集

- 可复现实例（仅示意）：
  - 提取（每中心一个源文件）：
    cpetx-data extract --input-root /path/raw_inputs \
      --output-root /path/extracted --schema-dir /root/autodl-tmp/vox_cpet/cpetformat \
      --institutes shanxi xuhui zhongshan --default-extractor cosmed 
  - 生成（standard 切分）：
    cpetx-data generate --input-root /path/extracted --institutes shanxi xuhui zhongshan \
      --output /path/datasets/cpet_dataset.h5 --train-ratio 0.7 --val-ratio 0.15 --test-ratio 0.15 \
      --columns-config /path/columns.yaml --aggregation-interval-seconds 10
  - 生成（LOCO）：
    cpetx-data generate --input-root /path/extracted --institutes shanxi xuhui zhongshan \
      --split-mode loco --output /path/datasets/cpet_dataset_loco/ --val-ratio 0.15 --random-seed 42 

- 验收：
  - `latexmk -pdf main.tex` 无警告；`main.log` 无 overfull/underfull boxes；
  - 数据集 HDF5 含有 `metadata/{feature_columns,target_columns,metadata_columns}`、`splits/{train,val,test}/features`、`metadata/splits_statistics`；
  - 若启用标准化，`splits/train/metadata/standardization/scaler_params/{mean,scale,standardized_columns}` 存在。

金标准定义 (Reference Standard):

(本部分是顶刊命脉) 详细描述“专家共识”流程。

示例: "所有 12,000 例数据均由两名经验超过10年的心肺功能专家 (A, B) 独立、盲法判读 AT (采用 V-slope 结合多图法)。若两人结果差异 < 5%，则取平均值。若差异 > 5%，则提交给第三位更资深的主任医师 (C) 进行最终裁决。该‘专家共识值’被作为模型训练和评估的唯一金标准。"

模型开发 (CPET-former 框架):

数据预处理: 保留原始分布、不过度优化；针对极端异常值做最小化处理：
  - Xuhui 中 \mbox{VE/VO2} 与 \mbox{VE/VCO2} 的异常比值：由于少量采样点 \mbox{VO2}/\mbox{VCO2} 近零导致比值膨胀，以上海中山+山西两中心观测到的最大值作为上限，超过者剔除；
  - 与临床读片口径对齐：对按呼吸频率采集的测试，做 10 s 窗聚合；窗口内对特征列按 IQR 规则做异常值过滤后取均值；
  - 轻量插值与最小缺失填充，仅为模型兼容性；
  - 标准化使用 z-score，仅在训练集拟合并作用于 val/test；必要时对目标同样处理。

模型族：
  - ML 基线：ridge/svr/random_forest/lightgbm，将时序汇总为表格特征（统计/趋势/领域特征+人口学）用于回归 VO2@AT。
  - cpet_former（ERM 基线）：Transformer 编码器 + 掩码池化 + 回归头，主任务 VO2@AT，可带 Time@AT 辅助损失。
  - cpet_former_center_film（已知中心增强）：中心嵌入 + per-layer FiLM（scale/shift）调制 token 表征，提升三中心混合数据集表现。
  - cpet_former_v1（未知中心增强）：按中心做 GroupDRO，加权最差中心的损失，提高 LOCO 下的最差中心性能。
  - cpet_former_v2（自监督+微调）：无标签预训练（masked reconstruction，可选对比头）→ 冻结/部分解冻微调预测头，少量标签（5–10%）达到接近全量监督性能。
  - 多目标版：共享主干 + 多输出头，同时预测 VO2@AT/Time@AT/HR@AT，支持辅助损失与权重。

传统 ML 基线: LightGBM, Random Forest, SVR (作为对比)。

多中心增强 (解决临床问题):

cpet_former_center_film: 解决已知中心/设备差异。

预期对比：
  1) cpet_former > 传统 ML（Mixed-CV）
  2) FiLM 在已知中心（Mixed-CV）优于 ERM
  3) GroupDRO 在未知中心（LOCO）优于 ERM，最差中心 MAE 显著下降
  4) 自监督（v2）在 5–10% 标签下接近/超过 ERM（Mixed-CV 和 LOCO）
  5) 多任务版在多指标上保持稳定（与单任务相近），证明任务泛化能力

cpet_former_v2 (SSL): 解决标签稀缺问题（模拟在新医院快速部署）。

多任务模型: 简述可同时预测 time_at_AT, hr_at_AT 等。

实验设计与统计分析:

数据集划分: 描述训练集、验证集、测试集 (例如按中心分层)。

实验 1: 内部验证 (Mixed-CV): 在混合数据上比较所有模型 (ML vs AI) 的性能。

实验 2: 泛化性验证 (LOCO): 关键实验。轮流使用两个中心的数据训练，在完全未见过的第三个中心上测试。这是评估 cpet_former_v1 的主要实验。

实验 3: 读者研究 (AI vs. Human):

样本: 从测试集中随机抽取 [例如 N=200] 例。

读者: 招募 [例如 12] 名医生（如 4 名初级、4 名中级、4 名高级专家），来自 [XX 医院，可非本研究中心]，对 200 例数据进行盲法判读。

对比: 将 AI 预测、12 名医生判读结果，共同与“金标准”进行比较。

实验 4: 次要分析 (SSL & 多任务): 评估 v2 的少样本性能和多任务模型的准确性。
  - 报告：标注占比（1/5/10/50%） vs MAE/$R^2$；多目标各指标 MAE。
  - 统计：与 ERM 配对检验；绘制学习曲线。

评估指标:

主要指标: $\text{VO}_2$ at AT 的平均绝对误差 (MAE)。

次要指标: 均方根误差 (RMSE), $R^2$, Bland-Altman 一致性分析。

一致性指标: 组内相关系数 (ICC) (用于评估人类医生间的变异性 vs AI)。

统计方法: 配对 t 检验、Wilcoxon 检验、ANOVA 等用于比较 MAE 差异。p < 0.05 视为显著。

3. 结果 (Results)

研究人群:

提供一个研究流程图 (Flow Chart)，显示从 [N] 例筛选到最终 12,000 例的过程。

Table 1 (基线表): 按三个中心展示患者的人口统计学、临床基线、CPET 基本结果（如 Peak $\text{VO}_2$），证明中心间的异质性。

实验 1 & 2: 模型性能与泛化性:

Table 2: 展示所有模型在 Mixed-CV 和 LOCO 上的 MAE/RMSE/$R^2$。

核心结果 1: cpet_former 显著优于所有 ML 模型 (p < 0.001)。

核心结果 2 (Figure 1 - LOCO): cpet_former_v1 (GroupDRO) 在 LOCO 上的 MAE 显著低于 cpet_former 基线模型，清晰展示其泛化能力。

实验 3: 读者研究 (AI vs. Human):

(本节是论文的“胜负手”)

Figure 2 (箱线图): 展示初级、中级、高级专家组以及 AI 模型的 MAE 分布。

核心结果 3 (文本): "AI 模型的 MAE 为 [X]，与高级专家组 (MAE [Y], p=n.s.) 表现相当，并显著优于初级 (MAE [Z], p<0.001) 和中级医生 (MAE [W], p<0.01)。"

Figure 3 (Bland-Altman 图): 视觉展示 AI vs 金标准、高级专家 vs 金标准之间的一致性。

核心结果 4 (一致性): "人类读者间的总体一致性为 [例如：ICC = 0.80 (95% CI: 0.75-0.84)]，显示出中度至良好的一致性。而 AI 模型的预测具有完美的可重复性 (ICC = 1.00)。"

实验 4: 次要分析:

Figure 4: SSL 学习曲线 (展示 cpet_former_v2 在 1%、5%、10%、50% 标注数据下的性能)。

Supplementary Table: 多任务模型的性能。

4. 讨论 (Discussion)

主要发现: 总结最重要的结果。

我们构建了一个大规模、标准化的多中心 CPET 数据集。

我们开发的 AI 框架（cpet_former_v1）在未知中心表现出强大的泛化能力，解决了 AI 临床部署的关键障碍。

在一项严格的盲法读者研究中，AI 的准确性媲美高级专家，且其完美的一致性解决了人工判读中固有的主观变异性问题。

与现有文献的联系:

对比其他 AI-CPET 研究（强调本研究在数据规模、多中心、泛化性验证和读者研究方面的开创性）。

讨论为何 Transformer 优于 ML（捕捉时序依赖）。

讨论 GroupDRO 带来的泛化性提升的临床意义（部署到新医院）。

优势 (Strengths):

数据集: 规模大、多中心、多设备。

金标准: 严格的“专家共识”流程，而非单一医生标注。

验证: 严谨的 LOCO（模拟真实世界泛化）+ 严格的读者研究（头对头比较）。

局限性 (Limitations):

回顾性研究设计（尽管数据收集是回顾性的，但分析是稳健的）。

中心和设备数量有限（虽然 3 个中心/2 种设备已是目前领先，但仍需更多样化的数据，如不同种族人群）。

未验证“在线预测”（实时性）。

未来方向与临床意义:

临床应用: 讨论该模型如何嵌入临床工作流（例如 EMR 或 CPET 设备软件），作为辅助诊断工具，减少医生负担，提高诊断同质化水平。

未来研究 (如您所列): 扩展到更多中心；在线预测；预测疾病（心梗）和终局事件（死亡率）。

5. 结论 (Conclusion)

简短有力。我们开发并严格验证了一个 AI 框架，它为 CPET 的 AT 评估提供了准确、客观且可泛化的解决方案。其媲美专家的性能和完美的一致性，使其成为标准化 CPET 临床实践的强大工具。

6. 参考文献 (References)

7. 补充材料 (Supplementary Material)

模型架构细节、超参数、数据标准化详细流程、所有次要结果的表格、Bland-Altman 全图等。

——

更新记录（2025-10-31）

目的：依据本文件大纲重构 main.tex，保持版式与风格不变，更新内容结构与叙事逻辑。

已执行的结构调整（对应 main.tex）：
- 摘要：按“背景-方法-结果-解读”四段重写，占位符保留，强调 LOCO 与读者研究。
- 引言：补充临床痛点与研究缺口；明确四项贡献与研究假说（AI 非劣于高级专家）。
- 方法：细化为 7 个小节，与大纲对齐。
  1) Study Design and Ethics（研究设计与伦理）
  2) Dataset and Standardization（数据收集与标准化，CPET-12k）
  3) Reference Standard（专家共识金标准）
  4) Model: CPET-former（模型）
  5) Training and Domain Generalization（训练与域泛化，GroupDRO）
  6) Evaluation Protocols（评估方案：Mixed-CV 与 LOCO）
  7) Blinded Reader Study（盲法读者研究）+ Interpretability and QC（可解释性与质控）
- 结果：
  - 新增研究流程图占位（fig:flow），新增基线表占位（tab:baseline）。
  - 保留并规范性能表（tab:perf），突出 LOCO 图（fig:loco）。
  - 读者研究箱线图（fig:reader）与 Bland–Altman 图（fig:ba）占位。
  - 次要分析：SSL 学习曲线（fig:ssl）占位。
- 数据集与补充材料：
  - 正文“数据”部分已精炼：仅保留来源/体量/标准与关键处理流程，弱化实现细节；突出模型主体。
  - 基线表保留；女比例/年龄/Peak VO2 仍为占位，待统一统计口径。
- 数据组织示意图保留（fig:data_org；figures/fig_data_organization.png）。
 - 数据集详情表新增（tab:dataset_details）：列出主数据集 train/val/test、按中心 30% 子集以及外部中心 punan/rizhao 的样本量、用途与标准化口径。
  - 详细特征清单移至补充表 S3（正文仅保留 Feature set 概览段）。
  - 新增分布概览图占位（fig:data_dist）：按中心展示 VO2、RER、VE、HR 的分布与缺失率注记。
  - 已加入简要描述性统计（正文数据段）：各中心 VO2_kg_at_AT（标准化）中位数（shanxi < 0；xuhui/zhongshan > 0）与典型测试时长中位数（约 10.0/15.8/18.0 分钟），用于辅助解释中心异质性。
- 讨论：对齐大纲的主要发现、文献关系、优势、局限与临床意义。
- 结论、作者声明、数据与代码可用性：语义收束；将长 URL 用 \url{} 处理。

版式与规范：
- 保持 Title Case 的章节标题；浮动体标签使用前缀 fig:/tab:；占位图采用 tcolorbox；图表引用为相对路径设计。
- 对长行与 URL 做断行/可断处理，清理 Overfull/Underfull box 警告（当前构建无警告）。

后续待补（替换占位并核对数值）：
- 人群 N、分中心样本量、设备型号与年限。
- 性能指标（MAE/RMSE/R^2，含 95% CI）、统计检验 p 值。
- 读者研究样本数、分层 MAE、ICC 与区间。
- SSL 不同标注比例下的曲线与具体数值。

对评审/协作的提示：
- 若后续引入新宏或包，请只在 main.tex 导言区相应注释块内添加，并保持两空格对齐的轻量缩进。
- 在替换图表时，将资产放入 figures/ 并使用相对路径 include；建议宽度统一为 \includegraphics[width=\linewidth]{...}。

更新记录（2025-11-03）
— main_clinical.tex 方法学更新 —
- Methods>Data and Harmonization（数据与标准化）已按 CPET 标准 v1.4（cpet.yaml v1.4.0）对齐：
  - 数据来源：三中心混合（zhongshan/xuhui/shanxi）为主数据集；外部中心 punan+rizhao 仅用于未知中心泛化评估；
  - 标准：统一字段/单位/类型（VE [L/min], VO2 [mL/min], VO2_kg [mL/kg/min], HR [1/min], PetO2/PetCO2 [mmHg], Power_Load [W], RPM [r/min], ST/S [mV]），时间语义（Time/Phase_Time mm:ss, Time_Relative s），Load_Phase 划分阶段；
  - 切分：按受试者分层随机切分 train/val/test，保持中心/设备比例，固定随机种子并冻结 split；基于混合数据集与显式外部测试；额外按中心抽样 30% primary dataset 作为快速探索子集；外部中心（punan、rizhao）作为独立测试集；外部测试的标准化参数仅由 primary dataset 的训练划分拟合并直接应用；
- 预处理：统一采样与 10 s 聚合；短缺口插值与最小填充；轻量、跨中心一致的异常值过滤；
 - 预处理（细化，替换 Preprocessing and robustness 文本）：
   • 原则：尽量保留原始分布，仅在出现极端异常值时做最小化处理；
   • Xuhui 的 \mbox{VE/VO2}, \mbox{VE/VCO2} 异常比值：以 Zhongshan+Shanxi 的最大值为阈上限，超限采样点剔除（源因为 \mbox{VO2}/\mbox{VCO2} 偶发近零）；
   • 与临床口径对齐：对呼吸频采样做 10 s 聚合，窗口内按 IQR 规则滤除异常后取均值；
   • 标准化：训练集拟合 z-score，固定应用于 val/test；必要时对目标同样处理；
  - 标准化：仅在训练集拟合（features/必要时 targets），应用到 val/test；评估在物理单位报告；
  - 标签：AT 标签由专家共识生成；AT 目标采用标准命名（VO2_kg_at_AT, HR_at_AT, Time_at_AT, RER_at_AT）。
