\documentclass[11pt, a4paper]{article}

%% ===== PACKAGES =====
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs} % Tables
\usepackage{hyperref} % Hyperlinks
\usepackage{geometry} % Margins
\usepackage{authblk}  % Author block
\usepackage{xcolor}   % Colors
\usepackage{tcolorbox} % Placeholders during drafting
\usepackage{lmodern}  % Modern font

%% === NO PARAGRAPH INDENTATION ===
\usepackage{parskip}

%% ===== DOCUMENT GEOMETRY =====
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

%% ===== HYPERLINK SETUP =====
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from CPET},
    pdfpagemode=FullScreen,
}

%% ===== TITLE AND AUTHOR INFORMATION =====
\title{\textbf{A Clinically Generalizable Artificial Intelligence for Automated Anaerobic Threshold Assessment from Cardiopulmonary Exercise Tests}\\\vspace{2pt}\large Multi-Center Standardization and Expert-Level Accuracy}
\author[1]{WANG Cong}
\author[2]{XU Bei}
\author[1]{MI Shou-ling\thanks{Corresponding author: email@address.com}}

\affil[1]{Zhongshan Hospital, Fudan University, China}
\affil[2]{}

\date{\today}

%% ===== BEGIN DOCUMENT =====
\begin{document}

\maketitle

%% Lightweight placeholder for numbers/centers/devices during drafting
\newcommand{\placeholder}[1]{\textcolor{red}{[#1]}}

\begin{abstract}
\noindent\textbf{Background}: Anaerobic threshold (AT) from cardiopulmonary exercise testing (CPET) guides risk stratification, perioperative triage, and rehabilitation. In practice, manual AT determination is subjective, time-consuming, and inconsistently standardized across centers/devices, limiting access and scale.

\noindent\textbf{Methods}: We assembled a large, multi-center, vendor-diverse CPET cohort (12{,}829 examinations) with cross-center/device harmonization. Expert consensus AT labels were obtained via two independent readers with blinded adjudication. We developed a transformer-based model (CPET-former) for multi-channel CPET time-series, introduced center-aware FiLM to model site/device effects, and used GroupDRO to improve robustness to unseen centers. Generalization was evaluated by a pooled, stratified 80\%/10\%/10\% train/validation/test split, and by testing on two external centers to simulate unseen centers. A blinded reader study compared AI with clinicians across seniority, and decision utility was assessed at VO\textsubscript{2}@AT thresholds (xx mL/kg/min).

\noindent\textbf{Findings}: CPET-former achieved expert-level accuracy with perfect reproducibility (ICC=xx). FiLM improved performance across known centers, and GroupDRO reduced worst-center error on external centers. In the reader study, AI was non-inferior to senior experts and outperformed junior/intermediate readers. Threshold analyses indicated favorable agreement and positive decision utility over clinically relevant ranges.

\noindent\textbf{Interpretation}: A clinically generalizable, auditable AI enables objective and consistent AT assessment across centers and devices. By aligning with expert performance and supporting decision thresholds, the framework can standardize CPET interpretation and reduce clinical workload.
\end{abstract}

\section{Introduction}

Cardiopulmonary exercise testing (CPET) informs risk stratification, perioperative triage, and rehabilitation planning \cite{guazzi2016}. Among CPET metrics, anaerobic threshold (AT) is widely used (e.g., VO\textsubscript{2}@AT near xx mL/kg/min) to guide decisions in heart failure and major surgery \cite{wasserman2012, beaver1986}. Yet, visual AT determination (e.g., V-slope) \cite{sue1988} is subjective, time-consuming, and inconsistently standardized, yielding modest inter-/intra-observer agreement \cite{yeh1983} and constraining real-world scale.

Existing automated methods (curve-fitting or limited ML) are sensitive to protocol/device variability and rarely validated across unseen centers \cite{santos2014, petek2021}. To expand equitable access to CPET-informed care, a clinically generalizable, auditable, and reproducible AT solution is needed.

We report a multi-center framework that unifies heterogeneous CPET data across vendors and delivers expert-level, reproducible AT assessment. Our contributions are: (i) a large, vendor-diverse cohort across three hospitals; (ii) cross-vendor signal harmonization; (iii) CPET-former, a transformer tailored to CPET time-series with center-aware FiLM for known-center generalization and GroupDRO for unseen-center robustness \cite{groupdro2020}; (iv) a blinded reader study spanning seniority; and (v) decision-utility analyses aligned to clinical thresholds. We hypothesize non-inferiority to senior experts with robust generalization and operational readiness.

\section{Methods}

\subsection{Design and Reference Standard}
We conducted a multi-center, retrospective diagnostic accuracy study with a prospective-simulated blinded reader study. Adults undergoing ramp-protocol CPET who met prespecified effort/quality criteria were included; incomplete or technically invalid files were excluded. Institutional review boards at \placeholder{Zhongshan}, \placeholder{Shanxi}, and \placeholder{Xuhui} approved the study with consent waived. The reference standard for AT was established by two independent readers with blinded adjudication of disagreements; readers were blinded to AI outputs and to each other. The primary endpoint was MAE of VO\textsubscript{2}@AT; secondary endpoints included RMSE, $R^2$, Bland–Altman, intraclass correlation coefficient (ICC), and calibration (slope/intercept). A clinically acceptable error band (e.g., \textpm1.0 mL/kg/min) was prespecified for interpretability. Subgroup analyses were prespecified by center, device, sex, age, and protocol duration.

\subsection{Data and Harmonization}
We curated 12{,}829 ramp-protocol examinations across three hospitals (Shanxi, Xuhui, Zhongshan) using two vendors (Ganshorn, COSMED). Two additional centers (punan, rizhao) were held out as external test sets to evaluate generalization to unseen centers.

\textbf{Data sources and standard.} We defined a CPET data standard and device-specific conversion protocols to harmonize heterogeneous exports across vendors. The standard covers breath-by-breath/second-by-second signals, summary endpoints, and metadata (see \texttt{/home/cheng/workspace/vox\_cpet/cpetformat/cpet.yaml}, CPET\_Standard\_v1.4). Based on this, we built the dataset with 69 feature channels, 4 AT targets, and 10 metadata fields (see \texttt{/home/cheng/workspace/vox\_cpet/template/dataset/configs/columns.yaml}). Names and units are normalized for ventilation and gas exchange (e.g., VE [L/min], VO\textsubscript{2} [mL/min], VO\textsubscript{2}/kg [mL/kg/min], VCO\textsubscript{2} [mL/min], RER), hemodynamics (HR [1/min], VO\textsubscript{2}/HR [mL/beat]), gas tensions (PetO\textsubscript{2}/PetCO\textsubscript{2} [mmHg]), workload (Power\_Load [W], RPM [r/min]), and ECG-derived features (ST/S amplitudes [mV]). Time is represented consistently via \texttt{Time}/\texttt{Phase\_Time} (mm:ss) and \texttt{Time\_Relative} (s); \texttt{Load\_Phase} delineates exercise stages. The dataset includes CPET time-series, expert consensus AT labels, and subject/examination metadata (center, device, protocol, demographics).

\textbf{Splits and evaluation.} The primary dataset is the pooled mix of Zhongshan/Xuhui/Shanxi. We performed stratified patient-level splits into train/validation/test (e.g., 80\%/10\%/10\%), preserving center/device proportions and preventing subject-level leakage; splits were seeded and frozen. Generalization was assessed by these pooled splits and by explicit external-center testing on punan/rizhao. Results are reported in physical units.

\textbf{Preprocessing and robustness.} To preserve real-world noise, we avoided over-optimization: signals were aligned and aggregated to 10 s windows, short gaps were interpolated with light QC, and missing values were minimally imputed for model compatibility. Because a few centers exhibited extreme outliers, we applied mild, cross-center-consistent outlier filtering. Standardization parameters (z-score) were fit on the training set and applied to validation/test for both features (and standardized targets where applicable). AT targets followed the standard nomenclature: \texttt{VO2\_kg\_at\_AT}, \texttt{HR\_at\_AT}, \texttt{Time\_at\_AT}, \texttt{RER\_at\_AT}. Further implementation details and full variable listings are provided in the Supplement.

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figures/fig_data_organization}
\caption{Overview of data sources, harmonization, and analysis splits.}
\label{fig:data_org}
\end{figure}

\subsection{Modeling and Evaluation}
We developed \textit{CPET-former}, a transformer-based model tailored to multi-channel CPET time-series that encodes breath-by-breath signals and aggregates sequence information to predict AT endpoints. To address multi-center generalization on known centers, we introduce center-aware Feature-wise Linear Modulation (FiLM): learned center embeddings explicitly modulate the backbone to capture site/device effects. For robustness to unseen centers, we adopt GroupDRO with centers as groups to optimize worst-center risk under distribution shift. Evaluation used MAE, RMSE, $R^2$, Bland–Altman, ICC, and calibration; decision utility was assessed at VO\textsubscript{2}@AT thresholds (xx mL/kg/min) via threshold agreement, net reclassification improvement (NRI), and decision curve analysis (DCA). Implementation details, hyperparameters, interpretability analyses, and full statistical outputs are provided in the Supplement.

\subsection{Reader Study}
We conducted a blinded reader study to test non-inferiority of AI to senior experts for VO\textsubscript{2}@AT estimation. Cases (\placeholder{N}) were stratified by center, device, protocol duration, and difficulty; readers were grouped by seniority (junior/intermediate/senior: \placeholder{J/I/S}) and received standardized training. Readers used a multi-panel interface (V-slope; VE/VO\textsubscript{2}; VE/VCO\textsubscript{2}; RER) and were blinded to the reference standard, to AI outputs, and to each other; a subset was re-read after a washout period (\placeholder{$\geq$2 weeks}) for intra-reader reliability. The primary endpoint was MAE of VO\textsubscript{2}@AT versus the reference standard with a prespecified non-inferiority margin $\delta$ (e.g., xx mL/kg/min); secondary endpoints included RMSE, $R^2$, Bland–Altman, ICC(2,1), calibration, and threshold utility at 11/14 mL/kg/min (agreement, NRI, DCA). Ethics approval and consent waiver were obtained (\placeholder{IRB refs}). Full procedural details are provided in Section~\textbf{Reader Study}.

\section{Results}

\subsection{Study Cohort}
The cohort comprised \placeholder{N} patients (age \placeholder{X}\,$\pm$\,\placeholder{Y} years; \placeholder{Z\%} female) across three centers and two devices. Protocols were predominantly ramp \placeholder{(X\%)} with median duration \placeholder{T} minutes.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Study flow diagram placeholder}]
Insert flow chart: screened $\rightarrow$ included $\rightarrow$ analysis sets (pooled train/val/test 80\%/10\%/10\%; two external centers as test).
\end{tcolorbox}
\caption{Study flow and analysis splits.}
\label{fig:flow}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Baseline characteristics by center.}
\label{tab:baseline}
\begin{tabular}{@{}lccc@{}}
\toprule
Characteristic & Shanxi & Xuhui & Zhongshan \\
\midrule
N (female \%) & 8785 (40.5\%) & 2411 (47.5\%) & 1633 (28.0\%) \\
Age (years) & $59.0\,\pm\,10.3$ & $59.0\,\pm\,13.4$ & $50.6\,\pm\,14.4$ \\
Peak VO\textsubscript{2} (mL/kg/min) & $13.9\,\pm\,3.6$ & $19.6\,\pm\,5.1$ & $20.2\,\pm\,5.8$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figures/fig_data_distributions}
\caption{Distribution snapshots (by center) for VO\textsubscript{2}, RER, VE, and HR in physical units; dashed lines indicate centre medians.}
\label{fig:data_dist}
\end{figure}

% Feature set overview (full spec in Supplementary Table S3)
\subsection{Clinical Threshold Agreement and Decision Utility}
We evaluated agreement at VO\textsubscript{2}@AT thresholds commonly used for risk stratification (e.g., 11 and 14 mL/kg/min). Outcome-oriented summaries included: (i) concordance rates and confusion matrices by threshold; (ii) net reclassification improvement (NRI) versus the reference standard; and (iii) decision curve analysis (DCA), which demonstrated positive net benefit across a wide threshold range.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Decision curve analysis (placeholder)}]
Insert DCA: net benefit versus threshold probability; compare AI-assisted vs. standard.\\ Highlight clinically relevant regions.
\end{tcolorbox}
\caption{Decision curve analysis for AI-assisted AT-based decision-making.}
\label{fig:dca}
\end{figure}

\noindent\textbf{Feature set.} The model consumes a comprehensive panel of ventilation, gas exchange, hemodynamic, and effort signals (e.g., VE, VO\textsubscript{2}, VCO\textsubscript{2}, RER, HR, Power\_Load, VT, Bf), alongside a small set of derived ratios. The full feature list with units and descriptions is provided in Supplementary Table S3.

\subsection{Model Performance and Generalization}
We compared CPET-former variants against Ridge/SVR/RF/LightGBM baselines. Metrics included MAE, RMSE, and $R^2$ with 95\% CIs; agreement was assessed via Bland–Altman and ICC.

On the pooled, stratified hold-out split, CPET-former (ERM) outperformed classical ML baselines. Centre-aware FiLM further improved performance across known centers, and on external centers, GroupDRO reduced worst-centre error and narrowed inter-centre variability (Table~\ref{tab:perf}; Figure~\ref{fig:loco}).

\begin{table}[htbp]
\centering
\caption{Model performance on the pooled hold-out and external centers (mean [95\% CI]).}
\label{tab:perf}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & Setting & MAE & RMSE & $R^2$ \\
\midrule
Linear/SVR/RF/LightGBM & Pooled hold-out & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (ERM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (FiLM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (GroupDRO) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (ERM) & External centers & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (GroupDRO) & External centers & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={External-center generalization placeholder}]
Insert center-wise MAE/RMSE for ERM vs GroupDRO;\\ highlight improvement at worst/unseen center.
\end{tcolorbox}
\caption{Performance on external centers by site.}
\label{fig:loco}
\end{figure}

\subsection{Reader Study: AI vs. Clinicians}
In the blinded reader study (\placeholder{N} cases), AI performance matched senior experts (MAE \placeholder{X} vs. \placeholder{Y}; $p=\,$n.s.) and exceeded junior/intermediate readers (MAE \placeholder{Z}; $p<0.001$). Inter-reader ICC was \placeholder{0.80} (95\% CI \placeholder{0.75--0.84}), whereas AI predictions were perfectly reproducible (ICC $=1.00$).

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Reader study boxplots placeholder}]
Insert boxplots of MAE by reader seniority vs AI.
\end{tcolorbox}
\caption{Reader study accuracy comparison.}
\label{fig:reader}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Bland–Altman plots placeholder}]
Insert Bland–Altman plots: (a) AI vs. consensus; (b) Senior vs. consensus.
\end{tcolorbox}
\caption{Agreement analyses against expert consensus.}
\label{fig:ba}
\end{figure}

% (Removed SSL learning curve figure to focus on supervised modeling and generalization analyses)

\section{Discussion}

\textbf{Principal findings.} We collected a large multi-center, vendor-diverse CPET cohort and developed CPET-former, a transformer-based model for multi-channel CPET time-series. Center-aware FiLM improved performance across known centers by capturing site/device effects, while GroupDRO reduced worst-center error on external centers, addressing a key barrier to clinical adoption. In a blinded reader study, AI achieved senior-expert accuracy and perfect reproducibility, overcoming inherent subjectivity in manual interpretation.

\textbf{Relation to prior work.} Prior AI-CPET studies are typically single-center with limited validation. Transformers capture long-range temporal dependencies \cite{vaswani2017}, aligning with the physiological progression of exercise. GroupDRO \cite{groupdro2020} minimizes worst-group risk, offering principled domain robustness in multi-center settings.

\textbf{Strengths.} (i) Scale and diversity across centers/devices; (ii) rigorous consensus ground truth; (iii) External-center validation approximating real-world practice; (iv) head-to-head comparison with clinicians; (v) interpretability analyses and QC of error cases.

\textbf{Limitations.} Retrospective design; limited number of centers/vendors; absence of prospective, point-of-care evaluation; demographics predominantly \placeholder{region}. Future work should broaden geography and device coverage, assess clinical adoption in service delivery settings, and quantify downstream clinical impact with uncertainty-aware safety monitoring.

\textbf{Clinical implications and future work.} In routine clinical practice (e.g., within reporting systems or device software), this approach can standardize CPET interpretation and reduce workload. Extending to multi-task outputs (e.g., VT1/VT2, peak VO\textsubscript{2}) and incorporating uncertainty quantification with conservative referral policies will support safe use and broader clinical adoption.

\section{Conclusion}

We present a generalizable AI framework for automated AT assessment that performs at senior-expert level with perfect reproducibility and robust cross-center generalization. By combining a transformer backbone with center-aware FiLM and GroupDRO, the approach addresses both known- and unseen-center variability. This enables standardized, scalable CPET interpretation in diverse clinical environments, supports standardized diagnostic pathways, and reduces clinical workload.

\newpage

% ===== BACKMATTER =====
\section*{Author Contributions}
B.X. conceived the study, designed the model, performed the analyses, and drafted the manuscript. C.W. acquired data, led clinical validation, and revised the manuscript. All authors approved the final manuscript.

\section*{Competing Interests}
B.X. is an employee of BexiMed Co., Ltd. C.W. declares no competing interests.

\section*{Data Availability}
The datasets generated and analyzed during the current study are not publicly available due to patient privacy regulations but are available from the corresponding author upon reasonable request and with appropriate institutional approvals.

\section*{Code Availability}
The CPET-former implementation and analysis scripts will be released upon publication at: \url{https://github.com/org/CPET-former}.

\section*{Supplementary Material}
\noindent\textbf{Supplementary Table S1. CPET Data Specification (overview).} The dataset contains 69 breath-by-breath feature channels grouped as follows: (i) Ventilation and gas exchange: VE, VO\textsubscript{2}, VCO\textsubscript{2}, VO\textsubscript{2}/kg, VE/VO\textsubscript{2}, VE/VCO\textsubscript{2}, VO\textsubscript{2}/HR; (ii) Respiratory timing and mechanics: Bf, VT, Ti, Te, Ttot, Ti/Ttot, VD/VT; (iii) Gas tensions: PetO\textsubscript{2}, PetCO\textsubscript{2}, PaO\textsubscript{2}, PaCO\textsubscript{2}, PaCO\textsubscript{2} (est.); (iv) Workload/protocol: Power\_Load, RPM, Load\_Phase; (v) Energy expenditure/substrate split: METS, EE (kcal/h; kg-normalized; total), CHO/Fat/PRO (kcal/h, kg-normalized, \%). ECG-derived signals include HR, HRR, and ST/S amplitudes across standard leads (I/II/III, aVR/aVL/aVF, V1--V6). Units are harmonized to L/min (VE), mL/min (VO\textsubscript{2}, VCO\textsubscript{2}), mL/kg/min (VO\textsubscript{2}/kg), bpm (HR), breaths/min (Bf), L (VT), W (Power\_Load), and unitless ratios for RER and ventilatory equivalents.

\noindent\textbf{Supplementary Table S2. Targets and metadata.} Targets: VO\textsubscript{2}/kg at AT (mL/kg/min), HR at AT (bpm), Time at AT (s), RER at AT (unitless). Key metadata: Examination\_ID, Subject\_ID, Time (timestamp), Gender, Age (years), Height\_cm, Weight\_kg, Source\_Device (Ganshorn/COSMED), Institute\_Name (Shanxi/Xuhui/Zhongshan).

% Auto-generated feature list table
\begin{table}[htbp]
\centering
\scriptsize
\caption{Full list of 69 feature columns.}
\label{tab:data_spec_full}
\begin{tabular}{@{}p{0.3\linewidth}p{0.3\linewidth}p{0.3\linewidth}@{}}
\toprule
Feature & Feature & Feature \\
\midrule
 Load\_Phase & BP\_Syst & ST\_II \\
 Bf & BP\_Diast & ST\_III \\
 BR\_pct & HRR & ST\_aVR \\
 VT & CO & ST\_aVL \\
 VE & PaO2 & ST\_aVF \\
 Ti & PaCO2 & ST\_V1 \\
 Te & PetO2 & ST\_V2 \\
 Ttot & PetCO2 & ST\_V3 \\
 Ti\_Ttot\_Ratio & Power\_Load & ST\_V4 \\
 VD\_VT\_Ratio & RPM & ST\_V5 \\
 VT\_Ti & EE\_Total\_kcal & ST\_V6 \\
 VO2 & EE\_kcal\_h & S\_I \\
 VO2\_kg & Fat\_kcal\_h & S\_II \\
 VCO2 & CHO\_kcal\_h & S\_III \\
 VCO2\_kg & PRO\_kcal\_h & S\_aVR \\
 RER & EE\_kg\_kcal\_h & S\_aVL \\
 PaCO2\_est & Fat\_kg\_kcal\_h & S\_aVF \\
 VE\_VO2 & CHO\_kg\_kcal\_h & S\_V1 \\
 VE\_VCO2 & PRO\_kg\_kcal\_h & S\_V2 \\
 METS & Fat\_pct & S\_V3 \\
 HR & CHO\_pct & S\_V4 \\
 VO2\_HR & PRO\_pct & S\_V5 \\
 SpO2 & ST\_I & S\_V6 \\
\bottomrule
\end{tabular}
\end{table}

\begin{thebibliography}{99}
% Existing references retained; added GroupDRO and ICC guidance
\bibitem{guazzi2016} Guazzi, M. et al. 2016 European Guidelines on cardiovascular disease prevention in clinical practice. \textit{Eur. Heart J.} \textbf{37}, 2315-2381 (2016).
\bibitem{wasserman2012} Wasserman, K., Hansen, J. E., Sue, D. Y., Stringer, W. W. \& Whipp, B. J. \textit{Principles of Exercise Testing and Interpretation} 5th edn (Lippincott Williams \& Wilkins, 2012).
\bibitem{beaver1986} Beaver, W. L., Wasserman, K. \& Whipp, B. J. A new method for detecting anaerobic threshold by gas exchange. \textit{J. Appl. Physiol.} \textbf{60}, 2020-2027 (1986).
\bibitem{sue1988} Sue, D. Y., Wasserman, K., Moricca, R. B. \& Casaburi, R. Metabolic acidosis during exercise in patients with chronic obstructive pulmonary disease. \textit{Chest} \textbf{94}, 931-938 (1988).
\bibitem{yeh1983} Yeh, M. P., Gardner, R. M., Adams, T. D., Yanowitz, F. G. \& Crapo, R. O. "Anaerobic threshold": problems of determination and validation. \textit{J. Appl. Physiol.} \textbf{55}, 1178-1186 (1983).
\bibitem{rajkomar2019} Rajkomar, A., Dean, J. \& Kohane, I. Machine learning in medicine. \textit{N. Engl. J. Med.} \textbf{380}, 1347-1358 (2019).
\bibitem{santos2014} Santos-Lozano, A. et al. A new algorithm to estimate anaerobic threshold based on heart rate variability. \textit{Comput. Methods Programs Biomed.} \textbf{114}, 8-14 (2014).
\bibitem{petek2021} Petek, B. J. et al. Machine learning for personalized cardiopulmonary exercise testing. \textit{Curr. Opin. Cardiol.} \textbf{36}, 549-557 (2021).
\bibitem{vaswani2017} Vaswani, A. et al. Attention is all you need. \textit{Adv. Neural Inf. Process. Syst.} \textbf{30}, 5998-6008 (2017).
\bibitem{devlin2018} Devlin, J., Chang, M. W., Lee, K. \& Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. \textit{arXiv preprint} arXiv:1810.04805 (2018).
\bibitem{dosovitskiy2020} Dosovitskiy, A. et al. An image is worth 16x16 words: Transformers for image recognition at scale. \textit{arXiv preprint} arXiv:2010.11929 (2020).
\bibitem{groupdro2020} Sagawa, S., Koh, P. W., Hashimoto, T. B. \& Liang, P. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. \textit{Proc. ICML} (2020).
\bibitem{koo2016} Koo, T. K. \& Li, M. Y. A guideline of selecting and reporting intraclass correlation coefficients for reliability research. \textit{J. Chiropr. Med.} \textbf{15}(2), 155--163 (2016).
\bibitem{ats2003} American Thoracic Society \& American College of Chest Physicians. ATS/ACCP Statement on cardiopulmonary exercise testing. \textit{Am. J. Respir. Crit. Care Med.} \textbf{167}, 211-277 (2003).
\end{thebibliography}

\vfill
\hrule
\footnotesize
\noindent\textit{Manuscript received: [Date]; accepted: [Date]; published online: [Date]} \\
\copyright~2025 The Author(s). This article is licensed under a Creative Commons Attribution 4.0 International License.

\end{document}
\documentclass[11pt, a4paper]{article}

%% ===== PACKAGES =====
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs} % Tables
\usepackage{hyperref} % Hyperlinks
\usepackage{geometry} % Margins
\usepackage{authblk}  % Author block
\usepackage{xcolor}   % Colors
\usepackage{tcolorbox} % Placeholders during drafting
\usepackage{lmodern}  % Modern font

%% === NO PARAGRAPH INDENTATION ===
\usepackage{parskip}

%% ===== DOCUMENT GEOMETRY =====
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

%% ===== HYPERLINK SETUP =====
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from CPET},
    pdfpagemode=FullScreen,
}

%% ===== TITLE AND AUTHOR INFORMATION =====
\title{\textbf{A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from Cardiopulmonary Exercise Tests}\\\vspace{2pt}\large A Diagnostic Accuracy and Reader Study}
\author[1]{WANG Cong}
\author[2]{XU Bei}
\author[1]{MI Shou-ling\thanks{Corresponding author: email@address.com}}

\affil[1]{Zhongshan Hospital, Fudan University, China}
\affil[2]{}

\date{\today}

%% ===== BEGIN DOCUMENT =====
\begin{document}

\maketitle

\begin{tcolorbox}[title={Key Messages},colback=gray!5,colframe=gray!40]
\small
- CPET-former delivers expert-level accuracy for AT and maintains performance at unseen centers (LOCO), enabling standardized interpretation across hospitals and devices.\\
- A large, multi-center, vendor-diverse CPET cohort (harmonized across centers/devices; 69 features, 4 AT targets) supports standardized diagnostic pathways and auditable, scalable clinical practice.\\
- Reader study shows non-inferiority to senior experts and superiority over junior/intermediate readers with perfect reproducibility, facilitating consistent decisions and reduced burden.\\
- Decision utility at clinical thresholds (e.g., 11/14 mL/kg/min) supports risk stratification and perioperative triage.
\end{tcolorbox}

%% Lightweight placeholder for numbers/centers/devices during drafting
\newcommand{\placeholder}[1]{\textcolor{red}{[#1]}}

\begin{abstract}
\noindent\textbf{Background}: The anaerobic threshold (AT) from cardiopulmonary exercise testing (CPET) is a key prognostic marker for risk stratification, perioperative assessment, and rehabilitation. Manual AT determination (e.g., V-slope) is time-consuming, experience-dependent, and exhibits substantial inter- and intra-observer variability, constraining scalability and standardization.

\noindent\textbf{Methods}: We curated CPET-12k, a standardized multi-center dataset of \placeholder{12,000} tests from three hospitals (\placeholder{Zhongshan}, \placeholder{Shanxi}, \placeholder{Xuhui}) and two device vendors (\placeholder{Ganshorn}, \placeholder{Cosmed}). Consensus ground truth was established via a two-reader protocol with blinded adjudication. We developed a transformer-based framework (\textit{CPET-former}) and applied GroupDRO \cite{groupdro2020} for domain generalization. Generalization was assessed via mixed cross-validation and leave-one-center-out (LOCO). We further conducted a blinded reader study with \placeholder{12} clinicians to compare AI against human readers across seniority.

\noindent\textbf{Findings}: CPET-former achieved strong internal accuracy for AT (MAE \placeholder{X}; $R^2$ \placeholder{X}). Under LOCO, GroupDRO improved performance at unseen centers (MAE \placeholder{X} vs. \placeholder{Y}; $p<0.01$). In the reader study, AI matched senior experts (MAE \placeholder{X} vs. \placeholder{Y}; $p=\,$n.s.) and exceeded junior/intermediate readers (MAE \placeholder{Z}; $p<0.001$). Inter-reader reliability was moderate (ICC \placeholder{0.78}), while AI predictions were perfectly reproducible (ICC $=1.00$). A self-supervised variant achieved \placeholder{\textasciitilde95\%} of full-data performance using \placeholder{10\%} labels.

\noindent\textbf{Interpretation}: We present a generalizable, objective, and highly consistent AI framework for automated AT assessment. The model demonstrates robust real-world performance, including at unseen centers, and achieves senior-expert-level accuracy with perfect reproducibility, enabling standardized CPET interpretation and reduced clinical burden.
\end{abstract}

\section{Introduction}

Cardiopulmonary exercise testing (CPET) integrates cardiovascular, pulmonary, and metabolic responses to exertion \cite{guazzi2016}. Among CPET-derived metrics, the anaerobic threshold (AT) is central to prognosis and decision-making in heart failure, perioperative risk, and rehabilitation \cite{wasserman2012, beaver1986}. Conventional AT determination via visual inspection (e.g., V-slope) \cite{sue1988} is subjective and labor-intensive. Inter- and intra-observer agreement can be modest even among experienced clinicians \cite{yeh1983}, compromising reproducibility and constraining scale.

Traditional automated approaches (e.g., curve-fitting) are sensitive to noise and protocol variability and often fail to generalize across vendors and clinical settings. Prior machine learning studies \cite{santos2014, petek2021} are typically single-center and small-scale, with limited validation on unseen centers. Robust generalization and head-to-head comparison with clinicians remain underexplored.

We address this gap with a multi-center, generalizable AI framework for automated AT assessment. Our aims are to deliver: (i) a large, standardized dataset (CPET-12k) spanning three centers and two device vendors; (ii) a transformer-based model (CPET-former) tailored to CPET time-series; (iii) domain generalization via GroupDRO to improve worst-center performance; and (iv) a blinded reader study benchmarking AI against clinicians. Our hypothesis is that AI accuracy and consistency are non-inferior to senior experts.

\section{Methods}

\subsection{Study Design and Ethics}
We conducted a multi-center, retrospective diagnostic accuracy study and a prospective-simulated blinded reader study. Institutional review board approvals were obtained at \placeholder{Zhongshan}, \placeholder{Shanxi}, and \placeholder{Xuhui} with consent waived.

\subsection{Dataset and Standardization (CPET-12k)}
CPET-12k comprises 12{,}829 ramp-protocol examinations from three hospitals (\textit{shanxi}, \textit{xuhui}, \textit{zhongshan}) and two vendors (Ganshorn, COSMED). Adults (\placeholder{$>$18} years) who completed maximal or symptom-limited CPET with acceptable quality per ATS/ACCP \cite{ats2003} were included; we excluded incomplete files, protocol deviations, and technical artifacts.

\textbf{Acquisition pipeline.} Raw vendor spreadsheets are converted to a unified CPET standard (v1.4) using a CLI (\texttt{cpetx-data extract}). Vendor-specific extractors (COSMED, Ganshorn) are driven by YAML mappings against a common schema. Device columns and summary cells are mapped to standard names/units then written to per-center HDF5 files named \texttt{cpet\_data\_source\_<center>.h5}. For this study, the immutable source HDF5 files are:
\begin{itemize}
  \item \path{/home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_shanxi.h5}
  \item \path{/home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_zhongshan.h5}
  \item \path{/home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_xuhui.h5}
\end{itemize}
These files are direct extracts from the original CPET exports using the CPET standard; beyond field naming/unit unification, no cleaning, interpolation, resampling, or feature engineering is applied at this stage.

\textbf{Standardization layer.} The CPET schema enumerates breath-by-breath fields, summary targets, and metadata types. Mappings apply unit conversions and normalization rules, for example: liters to mL/min for VO\textsubscript{2}/VCO\textsubscript{2} (Ganshorn), hPa to mmHg for barometric pressure, categorical encoding for gender, normalization of date/time strings, and mapping of phase markers to \texttt{Load\_Phase}. COSMED/Ganshorn adapters are specified in YAML and versioned with the schema for traceable harmonization (paths: \path{/root/autodl-tmp/vox_cpet/cpetformat/cpet.yaml}, \path{cosmed.yaml}, \path{ganshorn.yaml}).

\textbf{Cleaning and preprocessing.} From the per-center HDF5 sources, we construct an analysis-ready dataset via: (i) 10-second aggregation of breath-by-breath signals where applicable; (ii) per-examination linear interpolation with forward/backward fill for numeric channels; (iii) feature standardization using statistics fitted on the training split; and (iv) explicit feature/target extraction for AT-related endpoints (e.g., \texttt{VO2\_kg\_at\_AT}, \texttt{HR\_at\_AT}, \texttt{Time\_at\_AT}). The resulting processed dataset is stored at \path{/home/cheng/workspace/cpetx_workspace/cpet_former/artifacts/dataset/cpet_dataset.h5}. These steps are deterministic given the same inputs and seeds.

\textbf{Dataset generation and splits.} Processed center-wise frames are mixed into HDF5 datasets using \texttt{cpetx-data generate}. We support: (a) \textit{standard} splits that stratify examinations into train/val/test; (b) explicit center splits where train/val centers and a held-out test center are provided; and (c) leave-one-center-out (LOCO), producing one dataset per held-out center. Standardization uses a scaler fitted on the training split for user-specified feature columns and applied to val/test; scaler parameters (mean/scale) and the list of standardized features are stored in split metadata for inversion and audit.

\textbf{On-disk layout.} Final datasets contain two top-level groups: \texttt{metadata} and \texttt{splits}. The \texttt{metadata} group lists column categories (feature/target/metadata), split statistics (per split and per center), examination-to-center mapping, and standardization parameters. The \texttt{splits} group holds \texttt{train}, \texttt{val}, and \texttt{test}, each with columnar \texttt{features} and a \texttt{metadata} subgroup. Features include breath-by-breath signals such as \texttt{VE}, \texttt{VO2}, \texttt{VCO2}, \texttt{RER}, \texttt{HR}, \texttt{Power\_Load}, \texttt{VT}, \texttt{Bf}, and derived ratios (total \placeholder{69} channels). Targets include \texttt{VO2\_kg\_at\_AT}, \texttt{HR\_at\_AT}, \texttt{Time\_at\_AT}, and \texttt{RER\_at\_AT}. Representative split sizes (examinations): train 10{,}262; val 1{,}282; test 1{,}285 (total 12{,}829). Under LOCO, we release three folds with held-out \textit{shanxi} (8{,}785), \textit{xuhui} (2{,}411), and \textit{zhongshan} (1{,}633).

\textbf{Releases.} We provide the full mixed dataset and derived variants: 10\% subsamples for ablations (\texttt{*\_small}), self-supervised pretraining (\texttt{*\_ssl}), explicit train/val center splits with an external test set (\texttt{*\_explicit\_split}), and LOCO folds (\texttt{*\_loco}).

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figures/fig_data_organization}
\caption{Data packaging and split structure for CPET-12k.}
\label{fig:data_org}
\end{figure}

\subsection{Reference Standard (Expert Consensus)}
Ground truth AT was defined by a two-reader consensus process. Each case was independently annotated using V-slope corroborated by VE/VCO\textsubscript{2} nadir and ventilatory equivalents. Disagreements were resolved by blinded adjudication. Outlier and quality-control checks enforced physiological plausibility and protocol consistency.

\subsection{Model: CPET-former}
We evaluated a family of models for predicting the anaerobic threshold (AT) with VO\textsubscript{2}@AT as the primary endpoint, and optionally auxiliary targets (e.g., Time@AT, HR@AT).

\textbf{Classical ML baselines.} We include Ridge, SVR, Random Forest, and LightGBM. Time-series are summarized into tabular features (statistical moments, temporal trends/slopes, domain features such as peaks/threshold crossings) together with demographics, and regressed to VO\textsubscript{2}@AT. These serve as point-of-reference comparators.

\textbf{Baseline (cpet\_former).} A transformer encoder over breath-by-breath sequences with sinusoidal positional encoding and multi-head self-attention. The backbone projects input channels (e.g., VE, VO\textsubscript{2}, VCO\textsubscript{2}, RER, HR, Power\_Load, VT, Bf, time) to \texttt{d\_model}, stacks $L$ encoder blocks, and aggregates token features by masked mean pooling. A regression head outputs VO\textsubscript{2}@AT (and optionally Time@AT via an auxiliary head/loss). This is our empirical risk minimization (ERM) baseline on mixed-center data.

\textbf{Center-aware FiLM (cpet\_former\_center\_film).} To improve robustness on known centers, we inject centre embeddings via Feature-wise Linear Modulation: a learned centre vector adds a shallow bias before the encoder and generates per-layer scale/shift (FiLM) to modulate token features. This targets improved performance on the three-center mixed dataset without sacrificing overall accuracy.

\textbf{GroupDRO variant (cpet\_former\_v1).} To improve worst-centre performance under leave-one-center-out (LOCO), we adopt GroupDRO with centres as groups. Training uses per-sample MSE aggregated by a group-weighted objective with momentum-updated group losses and temperature-controlled softmax weighting, emphasizing the currently underperforming centre.

\textbf{Self-supervised pretraining (cpet\_former\_v2).} We pretrain the transformer backbone on unlabeled sequences via masked reconstruction (optionally with a contrastive projection head), then fine-tune a lightweight prediction head with few-shot labels. Backbones can be frozen or partially unfrozen during fine-tuning; pretrained weights are exportable/importable for reproducibility. This aims to retain strong accuracy with 5–10\% labeled data in both mixed-CV and LOCO.

\textbf{Multi-target variant.} A multi-output head (shared backbone) predicts multiple CPET endpoints jointly, e.g., VO\textsubscript{2}@AT, Time@AT, HR@AT, demonstrating that the architecture generalizes across related tasks. The trainer supports weighted auxiliary losses and head-wise diagnostics.

\subsection{Training and Domain Generalization}
Supervision uses MSE on VO\textsubscript{2}@AT as the primary loss; when enabled, Time@AT and HR@AT receive auxiliary losses with fixed weights. Optimization uses AdamW with cosine schedule and warmup; regularization includes dropout, segment mixup, and mild time-warp. For domain robustness: (i) \textit{FiLM} conditions the backbone on centre IDs for known-centre training; (ii) \textit{GroupDRO} reweights centre-wise losses to minimize worst-centre risk under distribution shift \cite{groupdro2020}. For \textit{SSL pretraining}, we mask valid timesteps and reconstruct inputs (with optional contrastive alignment between augmented views), then fine-tune the prediction head with frozen or partially unfrozen backbone.

\subsection{Evaluation Protocols}
We performed (i) stratified mixed $k$-fold cross-validation and (ii) leave-one-center-out (LOCO). Metrics included MAE, RMSE, $R^2$, and agreement analyses (Bland–Altman). Statistical testing used paired comparisons with Bonferroni correction. Calibration and failure modes were examined via error versus RER at AT and protocol duration.

\subsection{Blinded Reader Study}
\placeholder{N} cases were sampled to span diverse protocols and demographics. Readers (junior, intermediate, and senior) independently estimated AT using standardized software without access to ground truth or each other's labels.\\
After a washout period, a subset was repeated to evaluate intra-reader reliability. AI predictions were generated once per case without manual tuning. Agreement was quantified via ICC \cite{koo2016} and Bland–Altman.

\subsection{Interpretability and Quality Control}
We probed attention maps around predicted AT and inspected high-error cases for physiologic plausibility. We report representative cases and failure modes to guide clinical integration.

\section{Results}

\subsection{Study Cohort}
The cohort comprised \placeholder{N} patients (age \placeholder{X}\,$\pm$\,\placeholder{Y} years; \placeholder{Z\%} female) across three centers and two devices. Protocols were predominantly ramp \placeholder{(X\%)} with median duration \placeholder{T} minutes.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Study flow diagram placeholder}]
Insert flow chart: screened $\rightarrow$ included $\rightarrow$ analysis sets (train/val/test; LOCO folds).
\end{tcolorbox}
\caption{Study flow and analysis splits.}
\label{fig:flow}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Baseline characteristics by center.}
\label{tab:baseline}
\begin{tabular}{@{}lccc@{}}
\toprule
Characteristic & Shanxi & Xuhui & Zhongshan \\
\midrule
N (female \%) & 8785 (40.5\%) & 2411 (47.5\%) & 1633 (28.0\%) \\
Age (years) & $59.0\,\pm\,10.3$ & $59.0\,\pm\,13.4$ & $50.6\,\pm\,14.4$ \\
Peak VO\textsubscript{2} (mL/kg/min) & $13.9\,\pm\,3.6$ & $19.6\,\pm\,5.1$ & $20.2\,\pm\,5.8$ \\
\bottomrule
\end{tabular}
\end{table}

% Feature set overview (full spec in Supplementary Table S3)
\noindent\textbf{Feature set.} The model consumes a comprehensive panel of ventilation, gas exchange, hemodynamic, and effort signals (e.g., VE, VO\textsubscript{2}, VCO\textsubscript{2}, RER, HR, Power\_Load, VT, Bf), alongside a small set of derived ratios. The full feature list with units and descriptions is provided in Supplementary Table S3.

\subsection{Model Performance and Generalization}
We compared CPET-former variants against Ridge/SVR/RF/LightGBM baselines. Metrics included MAE, RMSE, and $R^2$ with 95\% CIs; agreement was assessed via Bland–Altman and ICC.

Across mixed cross-validation, CPET-former (ERM) outperformed classical ML baselines. Centre-aware FiLM further improved mixed-centre generalization, and on external centers, GroupDRO reduced worst-centre error and narrowed inter-centre variability. Self-supervised pretraining retained \placeholder{\textasciitilde95\%} of full-supervision accuracy with \placeholder{10\%} labels in both settings (Table~\ref{tab:perf}; Figure~\ref{fig:loco}).

\begin{table}[htbp]
\centering
\caption{Model performance in mixed CV and LOCO (mean [95\% CI]).}
\label{tab:perf}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & Setting & MAE & RMSE & $R^2$ \\
\midrule
Linear/SVR/RF/LightGBM & Pooled hold-out & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (ERM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (FiLM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (GroupDRO) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (ERM) & External centers & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (GroupDRO) & External centers & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (SSL few-shot) & Pooled hold-out/LOCO & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={External-center generalization placeholder}]
Insert center-wise MAE/RMSE for ERM vs GroupDRO;\\ highlight improvement at worst/unseen center.
\end{tcolorbox}
\caption{Performance on external centers by site.}
\label{fig:loco}
\end{figure}

\subsection{Reader Study: AI vs. Clinicians}
In the blinded reader study (\placeholder{N} cases), AI performance matched senior experts (MAE \placeholder{X} vs. \placeholder{Y}; $p=\,$n.s.) and exceeded junior/intermediate readers (MAE \placeholder{Z}; $p<0.001$). Inter-reader ICC was \placeholder{0.80} (95\% CI \placeholder{0.75--0.84}), whereas AI predictions were perfectly reproducible (ICC $=1.00$).

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Reader study boxplots placeholder}]
Insert boxplots of MAE by reader seniority vs AI.
\end{tcolorbox}
\caption{Reader study accuracy comparison.}
\label{fig:reader}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Bland–Altman plots placeholder}]
Insert Bland–Altman plots: (a) AI vs. consensus; (b) Senior vs. consensus.
\end{tcolorbox}
\caption{Agreement analyses against expert consensus.}
\label{fig:ba}
\end{figure}

\subsection{Secondary Analyses}
A self-supervised variant (\placeholder{CPET-former-SSL}) achieved \placeholder{\textasciitilde95\%} of full-supervision performance using \placeholder{10\%} labels (Figure~\ref{fig:ssl}); multi-task extensions are reported in the Supplement.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={SSL learning curve placeholder}]
Insert learning curve: labeled fraction vs. MAE/$R^2$.
\end{tcolorbox}
\caption{Label efficiency via self-supervision.}
\label{fig:ssl}
\end{figure}

\section{Discussion}

\textbf{Principal findings.} We built a large, standardized multi-center CPET dataset and developed an AI framework that achieves accurate, objective, and reproducible AT assessment. GroupDRO markedly improved generalization to unseen centers under LOCO, addressing a key barrier to clinical adoption. In a blinded reader study, AI achieved senior-expert accuracy and perfect reproducibility, overcoming inherent subjectivity in manual interpretation.

\textbf{Relation to prior work.} Prior AI-CPET studies are typically single-center with limited validation. Transformers capture long-range temporal dependencies \cite{vaswani2017}, aligning with the physiological progression of exercise. GroupDRO \cite{groupdro2020} minimizes worst-group risk, offering principled domain robustness in multi-center settings.

\textbf{Strengths.} (i) Scale and diversity across centers/devices; (ii) rigorous consensus ground truth; (iii) External-center validation approximating real-world practice; (iv) head-to-head comparison with clinicians; (v) interpretability analyses and QC of error cases.

\textbf{Limitations.} Retrospective design; limited number of centers/vendors; lack of real-time (online) validation; demographics predominantly \placeholder{region}. Future work should expand geography and device coverage, evaluate online inference, and examine downstream clinical impact.

\textbf{Clinical implications and future work.} In routine clinical practice (e.g., within reporting systems or device software), this approach can standardize CPET interpretation and reduce workload. Extending to multi-task outputs (e.g., VT1/VT2, peak VO\textsubscript{2}) and adding uncertainty quantification will broaden utility and support safe adoption.

\section{Conclusion}

We present a generalizable AI framework for automated AT assessment that performs at senior-expert level with perfect reproducibility and robust cross-center generalization. This enables standardized, scalable CPET interpretation in diverse clinical environments.

\newpage

% ===== BACKMATTER =====
\section*{Author Contributions}
B.X. conceived the study, designed the model, performed the analyses, and drafted the manuscript. C.W. acquired data, led clinical validation, and revised the manuscript. All authors approved the final manuscript.

\section*{Competing Interests}
B.X. is an employee of BexiMed Co., Ltd. C.W. declares no competing interests.

\section*{Data Availability}
The datasets generated and analyzed during the current study are not publicly available due to patient privacy regulations but are available from the corresponding author upon reasonable request and with appropriate institutional approvals.

\section*{Code Availability}
The CPET-former implementation and analysis scripts will be released upon publication at: \url{https://github.com/org/CPET-former}.

\section*{Supplementary Material}
\noindent\textbf{Supplementary Table S1. CPET Data Specification (overview).} The dataset contains 69 breath-by-breath feature channels grouped as follows: (i) Ventilation and gas exchange: VE, VO\textsubscript{2}, VCO\textsubscript{2}, VO\textsubscript{2}/kg, VE/VO\textsubscript{2}, VE/VCO\textsubscript{2}, VO\textsubscript{2}/HR; (ii) Respiratory timing and mechanics: Bf, VT, Ti, Te, Ttot, Ti/Ttot, VD/VT; (iii) Gas tensions: PetO\textsubscript{2}, PetCO\textsubscript{2}, PaO\textsubscript{2}, PaCO\textsubscript{2}, PaCO\textsubscript{2} (est.); (iv) Workload/protocol: Power\_Load, RPM, Load\_Phase; (v) Energy expenditure/substrate split: METS, EE (kcal/h; kg-normalized; total), CHO/Fat/PRO (kcal/h, kg-normalized, \%). ECG-derived signals include HR, HRR, and ST/S amplitudes across standard leads (I/II/III, aVR/aVL/aVF, V1--V6). Units are harmonized to L/min (VE), mL/min (VO\textsubscript{2}, VCO\textsubscript{2}), mL/kg/min (VO\textsubscript{2}/kg), bpm (HR), breaths/min (Bf), L (VT), W (Power\_Load), and unitless ratios for RER and ventilatory equivalents.

\noindent\textbf{Supplementary Table S2. Targets and metadata.} Targets: VO\textsubscript{2}/kg at AT (mL/kg/min), HR at AT (bpm), Time at AT (s), RER at AT (unitless). Key metadata: Examination\_ID, Subject\_ID, Time (timestamp), Gender, Age (years), Height\_cm, Weight\_kg, Source\_Device (Ganshorn/COSMED), Institute\_Name (Shanxi/Xuhui/Zhongshan).

% Auto-generated feature list table
\begin{table}[htbp]
\centering
\scriptsize
\caption{Full list of 69 feature columns.}
\label{tab:data_spec_full}
\begin{tabular}{@{}p{0.3\linewidth}p{0.3\linewidth}p{0.3\linewidth}@{}}
\toprule
Feature & Feature & Feature \\
\midrule
 Load\_Phase & BP\_Syst & ST\_II \\
 Bf & BP\_Diast & ST\_III \\
 BR\_pct & HRR & ST\_aVR \\
 VT & CO & ST\_aVL \\
 VE & PaO2 & ST\_aVF \\
 Ti & PaCO2 & ST\_V1 \\
 Te & PetO2 & ST\_V2 \\
 Ttot & PetCO2 & ST\_V3 \\
 Ti\_Ttot\_Ratio & Power\_Load & ST\_V4 \\
 VD\_VT\_Ratio & RPM & ST\_V5 \\
 VT\_Ti & EE\_Total\_kcal & ST\_V6 \\
 VO2 & EE\_kcal\_h & S\_I \\
 VO2\_kg & Fat\_kcal\_h & S\_II \\
 VCO2 & CHO\_kcal\_h & S\_III \\
 VCO2\_kg & PRO\_kcal\_h & S\_aVR \\
 RER & EE\_kg\_kcal\_h & S\_aVL \\
 PaCO2\_est & Fat\_kg\_kcal\_h & S\_aVF \\
 VE\_VO2 & CHO\_kg\_kcal\_h & S\_V1 \\
 VE\_VCO2 & PRO\_kg\_kcal\_h & S\_V2 \\
 METS & Fat\_pct & S\_V3 \\
 HR & CHO\_pct & S\_V4 \\
 VO2\_HR & PRO\_pct & S\_V5 \\
 SpO2 & ST\_I & S\_V6 \\
\bottomrule
\end{tabular}
\end{table}

\begin{thebibliography}{99}
% Existing references retained; added GroupDRO and ICC guidance
\bibitem{guazzi2016} Guazzi, M. et al. 2016 European Guidelines on cardiovascular disease prevention in clinical practice. \textit{Eur. Heart J.} \textbf{37}, 2315-2381 (2016).
\bibitem{wasserman2012} Wasserman, K., Hansen, J. E., Sue, D. Y., Stringer, W. W. \& Whipp, B. J. \textit{Principles of Exercise Testing and Interpretation} 5th edn (Lippincott Williams \& Wilkins, 2012).
\bibitem{beaver1986} Beaver, W. L., Wasserman, K. \& Whipp, B. J. A new method for detecting anaerobic threshold by gas exchange. \textit{J. Appl. Physiol.} \textbf{60}, 2020-2027 (1986).
\bibitem{sue1988} Sue, D. Y., Wasserman, K., Moricca, R. B. \& Casaburi, R. Metabolic acidosis during exercise in patients with chronic obstructive pulmonary disease. \textit{Chest} \textbf{94}, 931-938 (1988).
\bibitem{yeh1983} Yeh, M. P., Gardner, R. M., Adams, T. D., Yanowitz, F. G. \& Crapo, R. O. "Anaerobic threshold": problems of determination and validation. \textit{J. Appl. Physiol.} \textbf{55}, 1178-1186 (1983).
\bibitem{rajkomar2019} Rajkomar, A., Dean, J. \& Kohane, I. Machine learning in medicine. \textit{N. Engl. J. Med.} \textbf{380}, 1347-1358 (2019).
\bibitem{santos2014} Santos-Lozano, A. et al. A new algorithm to estimate anaerobic threshold based on heart rate variability. \textit{Comput. Methods Programs Biomed.} \textbf{114}, 8-14 (2014).
\bibitem{petek2021} Petek, B. J. et al. Machine learning for personalized cardiopulmonary exercise testing. \textit{Curr. Opin. Cardiol.} \textbf{36}, 549-557 (2021).
\bibitem{vaswani2017} Vaswani, A. et al. Attention is all you need. \textit{Adv. Neural Inf. Process. Syst.} \textbf{30}, 5998-6008 (2017).
\bibitem{devlin2018} Devlin, J., Chang, M. W., Lee, K. \& Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. \textit{arXiv preprint} arXiv:1810.04805 (2018).
\bibitem{dosovitskiy2020} Dosovitskiy, A. et al. An image is worth 16x16 words: Transformers for image recognition at scale. \textit{arXiv preprint} arXiv:2010.11929 (2020).
\bibitem{groupdro2020} Sagawa, S., Koh, P. W., Hashimoto, T. B. \& Liang, P. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. \textit{Proc. ICML} (2020).
\bibitem{koo2016} Koo, T. K. \& Li, M. Y. A guideline of selecting and reporting intraclass correlation coefficients for reliability research. \textit{J. Chiropr. Med.} \textbf{15}(2), 155--163 (2016).
\bibitem{ats2003} American Thoracic Society \& American College of Chest Physicians. ATS/ACCP Statement on cardiopulmonary exercise testing. \textit{Am. J. Respir. Crit. Care Med.} \textbf{167}, 211-277 (2003).
\end{thebibliography}

\vfill
\hrule
\footnotesize
\noindent\textit{Manuscript received: [Date]; accepted: [Date]; published online: [Date]} \\
\copyright~2025 The Author(s). This article is licensed under a Creative Commons Attribution 4.0 International License.

\end{document}
\documentclass[11pt, a4paper]{article}

%% ===== PACKAGES =====
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs} % Tables
\usepackage{hyperref} % Hyperlinks
\usepackage{geometry} % Margins
\usepackage{authblk}  % Author block
\usepackage{xcolor}   % Colors
\usepackage{tcolorbox} % Placeholders during drafting
\usepackage{lmodern}  % Modern font

%% === NO PARAGRAPH INDENTATION ===
\usepackage{parskip}

%% ===== DOCUMENT GEOMETRY =====
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

%% ===== HYPERLINK SETUP =====
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from CPET},
    pdfpagemode=FullScreen,
}

%% ===== TITLE AND AUTHOR INFORMATION =====
\title{\textbf{A Clinically Generalizable AI for Automated Anaerobic Threshold Assessment from Cardiopulmonary Exercise Tests}\\\vspace{2pt}\large Multi-Center Standardization and Expert-Level Accuracy}
\author[1]{WANG Cong}
\author[2]{XU Bei}
\author[1]{MI Shou-ling\thanks{Corresponding author: email@address.com}}

\affil[1]{Zhongshan Hospital, Fudan University, China}
\affil[2]{}

\date{\today}

%% ===== BEGIN DOCUMENT =====
\begin{document}

\maketitle

%% Lightweight placeholder for numbers/centers/devices during drafting
\newcommand{\placeholder}[1]{\textcolor{red}{[#1]}}

\begin{abstract}
\noindent\textbf{Background}: Anaerobic threshold (AT) from cardiopulmonary exercise testing (CPET) guides risk stratification, perioperative triage, and rehabilitation. In practice, manual AT determination is subjective, time-consuming, and inconsistently standardized across centers/devices, limiting access and scale.

\noindent\textbf{Methods}: We assembled a large, multi-center, vendor-diverse CPET cohort (12{,}829 examinations) with cross-center/device harmonization. Expert consensus AT labels were obtained via two independent readers with blinded adjudication. We developed a transformer-based model (CPET-former) for multi-channel CPET time-series, introduced center-aware FiLM to model site/device effects, and used GroupDRO to improve robustness to unseen centers. Generalization was evaluated by a pooled, stratified 80\%/10\%/10\% train/validation/test split, and by testing on two external centers to simulate unseen centers. A blinded reader study compared AI with clinicians across seniority, and decision utility was assessed at VO\textsubscript{2}@AT thresholds (xx mL/kg/min).

\noindent\textbf{Findings}: CPET-former achieved expert-level accuracy with perfect reproducibility (ICC=xx). FiLM improved performance across known centers, and GroupDRO reduced worst-center error on external centers. In the reader study, AI was non-inferior to senior experts and outperformed junior/intermediate readers. Threshold analyses indicated favorable agreement and positive decision utility over clinically relevant ranges.

\noindent\textbf{Interpretation}: A clinically generalizable, auditable AI enables objective and consistent AT assessment across centers and devices. By aligning with expert performance and supporting decision thresholds, the framework can standardize CPET interpretation and reduce clinical workload.
\end{abstract}

\section{Introduction}

Cardiopulmonary exercise testing (CPET) informs risk stratification, perioperative triage, and rehabilitation planning \cite{guazzi2016}. Among CPET metrics, anaerobic threshold (AT) is widely used (e.g., VO\textsubscript{2}@AT near xx mL/kg/min) to guide decisions in heart failure and major surgery \cite{wasserman2012, beaver1986}. Yet, visual AT determination (e.g., V-slope) \cite{sue1988} is subjective, time-consuming, and inconsistently standardized, yielding modest inter-/intra-observer agreement \cite{yeh1983} and constraining real-world scale.

Existing automated methods (curve-fitting or limited ML) are sensitive to protocol/device variability and rarely validated across unseen centers \cite{santos2014, petek2021}. To expand equitable access to CPET-informed care, a clinically generalizable, auditable, and reproducible AT solution is needed.

We report a multi-center framework that unifies heterogeneous CPET data across vendors and delivers expert-level, reproducible AT assessment. Our contributions are: (i) a large, vendor-diverse cohort across three hospitals; (ii) cross-vendor signal harmonization; (iii) CPET-former, a transformer tailored to CPET time-series with center-aware FiLM for known-center generalization and GroupDRO for unseen-center robustness \cite{groupdro2020}; (iv) a blinded reader study spanning seniority; and (v) decision-utility analyses aligned to clinical thresholds. We hypothesize non-inferiority to senior experts with robust generalization and operational readiness.

\section{Methods}

\subsection{Design and Reference Standard}
We conducted a multi-center, retrospective diagnostic accuracy study with a prospective-simulated blinded reader study. Adults undergoing ramp-protocol CPET who met prespecified effort/quality criteria were included; incomplete or technically invalid files were excluded. Institutional review boards at \placeholder{Zhongshan}, \placeholder{Shanxi}, and \placeholder{Xuhui} approved the study with consent waived. The reference standard for AT was established by two independent readers with blinded adjudication of disagreements; readers were blinded to AI outputs and to each other. The primary endpoint was MAE of VO\textsubscript{2}@AT; secondary endpoints included RMSE, $R^2$, Bland–Altman, intraclass correlation coefficient (ICC), and calibration (slope/intercept). A clinically acceptable error band (e.g., \textpm1.0 mL/kg/min) was prespecified for interpretability. Subgroup analyses were prespecified by center, device, sex, age, and protocol duration.

\subsection{Data and Harmonization}
We collected 12{,}829 ramp-protocol examinations from three hospitals (Shanxi, Xuhui, Zhongshan) using two vendors (Ganshorn, COSMED). To enable pooled analyses across centers/devices, variable names and units for breath-by-breath signals and summary targets were harmonized to a consistent schema. The dataset includes 69 input features and 4 AT-related targets (VO\textsubscript{2}\_kg\_at\_AT, HR\_at\_AT, Time\_at\_AT, RER\_at\_AT). Key processing comprised 10-second aggregation, short-gap interpolation with light quality control, and training-split standardization (parameters learned on train and applied to validation/test). We used a single, stratified hold-out split on the pooled multi-center cohort into train/validation/test (80\%/10\%/10\%), at the patient level to prevent leakage, with stratification by center and device to preserve marginal distributions; a fixed random seed was used and split indices were frozen for all experiments. Two external centers were held out as test sets to evaluate generalization to unseen centers.

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figures/fig_data_organization}
\caption{Overview of data sources, harmonization, and analysis splits.}
\label{fig:data_org}
\end{figure}

\subsection{Modeling and Evaluation}
We developed \textit{CPET-former}, a transformer-based model tailored to multi-channel CPET time-series that encodes breath-by-breath signals and aggregates sequence information to predict AT endpoints. To address multi-center generalization on known centers, we introduce center-aware Feature-wise Linear Modulation (FiLM): learned center embeddings explicitly modulate the backbone to capture site/device effects. For robustness to unseen centers, we adopt GroupDRO with centers as groups to optimize worst-center risk under distribution shift. Evaluation used MAE, RMSE, $R^2$, Bland–Altman, ICC, and calibration; decision utility was assessed at VO\textsubscript{2}@AT thresholds (xx mL/kg/min) via threshold agreement, net reclassification improvement (NRI), and decision curve analysis (DCA). Implementation details, hyperparameters, interpretability analyses, and full statistical outputs are provided in the Supplement.

\subsection{Reader Study}
We conducted a blinded reader study to test non-inferiority of AI to senior experts for VO\textsubscript{2}@AT estimation. Cases (\placeholder{N}) were stratified by center, device, protocol duration, and difficulty; readers were grouped by seniority (junior/intermediate/senior: \placeholder{J/I/S}) and received standardized training. Readers used a multi-panel interface (V-slope; VE/VO\textsubscript{2}; VE/VCO\textsubscript{2}; RER) and were blinded to the reference standard, to AI outputs, and to each other; a subset was re-read after a washout period (\placeholder{$\geq$2 weeks}) for intra-reader reliability. The primary endpoint was MAE of VO\textsubscript{2}@AT versus the reference standard with a prespecified non-inferiority margin $\delta$ (e.g., xx mL/kg/min); secondary endpoints included RMSE, $R^2$, Bland–Altman, ICC(2,1), calibration, and threshold utility at 11/14 mL/kg/min (agreement, NRI, DCA). Ethics approval and consent waiver were obtained (\placeholder{IRB refs}). Full procedural details are provided in Section~\textbf{Reader Study}.

\section{Results}

\subsection{Study Cohort}
The cohort comprised \placeholder{N} patients (age \placeholder{X}\,$\pm$\,\placeholder{Y} years; \placeholder{Z\%} female) across three centers and two devices. Protocols were predominantly ramp \placeholder{(X\%)} with median duration \placeholder{T} minutes.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Study flow diagram placeholder}]
Insert flow chart: screened $\rightarrow$ included $\rightarrow$ analysis sets (pooled train/val/test 80%/10%/10%; two external centers as test).
\end{tcolorbox}
\caption{Study flow and analysis splits.}
\label{fig:flow}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Baseline characteristics by center.}
\label{tab:baseline}
\begin{tabular}{@{}lccc@{}}
\toprule
Characteristic & Shanxi & Xuhui & Zhongshan \\
\midrule
N (female \%) & 8785 (40.5\%) & 2411 (47.5\%) & 1633 (28.0\%) \\
Age (years) & $59.0\,\pm\,10.3$ & $59.0\,\pm\,13.4$ & $50.6\,\pm\,14.4$ \\
Peak VO\textsubscript{2} (mL/kg/min) & $13.9\,\pm\,3.6$ & $19.6\,\pm\,5.1$ & $20.2\,\pm\,5.8$ \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figures/fig_data_distributions}
\caption{Distribution snapshots (by center) for VO\textsubscript{2}, RER, VE, and HR in physical units; dashed lines indicate centre medians.}
\label{fig:data_dist}
\end{figure}

% Feature set overview (full spec in Supplementary Table S3)
\subsection{Clinical Threshold Agreement and Decision Utility}
We evaluated agreement at VO\textsubscript{2}@AT thresholds commonly used for risk stratification (e.g., 11 and 14 mL/kg/min). Outcome-oriented summaries included: (i) concordance rates and confusion matrices by threshold; (ii) net reclassification improvement (NRI) versus the reference standard; and (iii) decision curve analysis (DCA), which demonstrated positive net benefit across a wide threshold range.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Decision curve analysis (placeholder)}]
Insert DCA: net benefit versus threshold probability; compare AI-assisted vs. standard.\\ Highlight clinically relevant regions.
\end{tcolorbox}
\caption{Decision curve analysis for AI-assisted AT-based decision-making.}
\label{fig:dca}
\end{figure}

\noindent\textbf{Feature set.} The model consumes a comprehensive panel of ventilation, gas exchange, hemodynamic, and effort signals (e.g., VE, VO\textsubscript{2}, VCO\textsubscript{2}, RER, HR, Power\_Load, VT, Bf), alongside a small set of derived ratios. The full feature list with units and descriptions is provided in Supplementary Table S3.

\subsection{Model Performance and Generalization}
We compared CPET-former variants against Ridge/SVR/RF/LightGBM baselines. Metrics included MAE, RMSE, and $R^2$ with 95\% CIs; agreement was assessed via Bland–Altman and ICC.

On the pooled, stratified hold-out split, CPET-former (ERM) outperformed classical ML baselines. Centre-aware FiLM further improved performance across known centers, and on external centers, GroupDRO reduced worst-centre error and narrowed inter-centre variability (Table~\ref{tab:perf}; Figure~\ref{fig:loco}).

\begin{table}[htbp]
\centering
\caption{Model performance on the pooled hold-out and external centers (mean [95\% CI]).}
\label{tab:perf}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & Setting & MAE & RMSE & $R^2$ \\
\midrule
Linear/SVR/RF/LightGBM & Pooled hold-out & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (ERM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (FiLM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (GroupDRO) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (ERM) & External centers & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (GroupDRO) & External centers & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={External-center generalization placeholder}]
Insert center-wise MAE/RMSE for ERM vs GroupDRO;\\ highlight improvement at worst/unseen center.
\end{tcolorbox}
\caption{Performance on external centers by site.}
\label{fig:loco}
\end{figure}

\subsection{Reader Study: AI vs. Clinicians}
In the blinded reader study (\placeholder{N} cases), AI performance matched senior experts (MAE \placeholder{X} vs. \placeholder{Y}; $p=\,$n.s.) and exceeded junior/intermediate readers (MAE \placeholder{Z}; $p<0.001$). Inter-reader ICC was \placeholder{0.80} (95\% CI \placeholder{0.75--0.84}), whereas AI predictions were perfectly reproducible (ICC $=1.00$).

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Reader study boxplots placeholder}]
Insert boxplots of MAE by reader seniority vs AI.
\end{tcolorbox}
\caption{Reader study accuracy comparison.}
\label{fig:reader}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Bland–Altman plots placeholder}]
Insert Bland–Altman plots: (a) AI vs. consensus; (b) Senior vs. consensus.
\end{tcolorbox}
\caption{Agreement analyses against expert consensus.}
\label{fig:ba}
\end{figure}

% (Removed SSL learning curve figure to focus on supervised modeling and generalization analyses)

\section{Discussion}

\textbf{Principal findings.} We collected a large multi-center, vendor-diverse CPET cohort and developed CPET-former, a transformer-based model for multi-channel CPET time-series. Center-aware FiLM improved performance across known centers by capturing site/device effects, while GroupDRO reduced worst-center error on external centers, addressing a key barrier to clinical adoption. In a blinded reader study, AI achieved senior-expert accuracy and perfect reproducibility, overcoming inherent subjectivity in manual interpretation.

\textbf{Relation to prior work.} Prior AI-CPET studies are typically single-center with limited validation. Transformers capture long-range temporal dependencies \cite{vaswani2017}, aligning with the physiological progression of exercise. GroupDRO \cite{groupdro2020} minimizes worst-group risk, offering principled domain robustness in multi-center settings.

\textbf{Strengths.} (i) Scale and diversity across centers/devices; (ii) rigorous consensus ground truth; (iii) External-center validation approximating real-world practice; (iv) head-to-head comparison with clinicians; (v) interpretability analyses and QC of error cases.

\textbf{Limitations.} Retrospective design; limited number of centers/vendors; absence of prospective, point-of-care evaluation; demographics predominantly \placeholder{region}. Future work should broaden geography and device coverage, assess clinical adoption in service delivery settings, and quantify downstream clinical impact with uncertainty-aware safety monitoring.

\textbf{Clinical implications and future work.} In routine clinical practice (e.g., within reporting systems or device software), this approach can standardize CPET interpretation and reduce workload. Extending to multi-task outputs (e.g., VT1/VT2, peak VO\textsubscript{2}) and incorporating uncertainty quantification with conservative referral policies will support safe use and broader clinical adoption.

\section{Conclusion}

We present a generalizable AI framework for automated AT assessment that performs at senior-expert level with perfect reproducibility and robust cross-center generalization. By combining a transformer backbone with center-aware FiLM and GroupDRO, the approach addresses both known- and unseen-center variability. This enables standardized, scalable CPET interpretation in diverse clinical environments, supports standardized diagnostic pathways, and reduces clinical workload.

\newpage

% ===== BACKMATTER =====
\section*{Author Contributions}
B.X. conceived the study, designed the model, performed the analyses, and drafted the manuscript. C.W. acquired data, led clinical validation, and revised the manuscript. All authors approved the final manuscript.

\section*{Competing Interests}
B.X. is an employee of BexiMed Co., Ltd. C.W. declares no competing interests.

\section*{Data Availability}
The datasets generated and analyzed during the current study are not publicly available due to patient privacy regulations but are available from the corresponding author upon reasonable request and with appropriate institutional approvals.

\section*{Code Availability}
The CPET-former implementation and analysis scripts will be released upon publication at: \url{https://github.com/org/CPET-former}.

\section*{Supplementary Material}
\noindent\textbf{Supplementary Table S1. CPET Data Specification (overview).} The dataset contains 69 breath-by-breath feature channels grouped as follows: (i) Ventilation and gas exchange: VE, VO\textsubscript{2}, VCO\textsubscript{2}, VO\textsubscript{2}/kg, VE/VO\textsubscript{2}, VE/VCO\textsubscript{2}, VO\textsubscript{2}/HR; (ii) Respiratory timing and mechanics: Bf, VT, Ti, Te, Ttot, Ti/Ttot, VD/VT; (iii) Gas tensions: PetO\textsubscript{2}, PetCO\textsubscript{2}, PaO\textsubscript{2}, PaCO\textsubscript{2}, PaCO\textsubscript{2} (est.); (iv) Workload/protocol: Power\_Load, RPM, Load\_Phase; (v) Energy expenditure/substrate split: METS, EE (kcal/h; kg-normalized; total), CHO/Fat/PRO (kcal/h, kg-normalized, \%). ECG-derived signals include HR, HRR, and ST/S amplitudes across standard leads (I/II/III, aVR/aVL/aVF, V1--V6). Units are harmonized to L/min (VE), mL/min (VO\textsubscript{2}, VCO\textsubscript{2}), mL/kg/min (VO\textsubscript{2}/kg), bpm (HR), breaths/min (Bf), L (VT), W (Power\_Load), and unitless ratios for RER and ventilatory equivalents.

\noindent\textbf{Supplementary Table S2. Targets and metadata.} Targets: VO\textsubscript{2}/kg at AT (mL/kg/min), HR at AT (bpm), Time at AT (s), RER at AT (unitless). Key metadata: Examination\_ID, Subject\_ID, Time (timestamp), Gender, Age (years), Height\_cm, Weight\_kg, Source\_Device (Ganshorn/COSMED), Institute\_Name (Shanxi/Xuhui/Zhongshan).

% Auto-generated feature list table
\begin{table}[htbp]
\centering
\scriptsize
\caption{Full list of 69 feature columns.}
\label{tab:data_spec_full}
\begin{tabular}{@{}p{0.3\linewidth}p{0.3\linewidth}p{0.3\linewidth}@{}}
\toprule
Feature & Feature & Feature \\
\midrule
 Load\_Phase & BP\_Syst & ST\_II \\
 Bf & BP\_Diast & ST\_III \\
 BR\_pct & HRR & ST\_aVR \\
 VT & CO & ST\_aVL \\
 VE & PaO2 & ST\_aVF \\
 Ti & PaCO2 & ST\_V1 \\
 Te & PetO2 & ST\_V2 \\
 Ttot & PetCO2 & ST\_V3 \\
 Ti\_Ttot\_Ratio & Power\_Load & ST\_V4 \\
 VD\_VT\_Ratio & RPM & ST\_V5 \\
 VT\_Ti & EE\_Total\_kcal & ST\_V6 \\
 VO2 & EE\_kcal\_h & S\_I \\
 VO2\_kg & Fat\_kcal\_h & S\_II \\
 VCO2 & CHO\_kcal\_h & S\_III \\
 VCO2\_kg & PRO\_kcal\_h & S\_aVR \\
 RER & EE\_kg\_kcal\_h & S\_aVL \\
 PaCO2\_est & Fat\_kg\_kcal\_h & S\_aVF \\
 VE\_VO2 & CHO\_kg\_kcal\_h & S\_V1 \\
 VE\_VCO2 & PRO\_kg\_kcal\_h & S\_V2 \\
 METS & Fat\_pct & S\_V3 \\
 HR & CHO\_pct & S\_V4 \\
 VO2\_HR & PRO\_pct & S\_V5 \\
 SpO2 & ST\_I & S\_V6 \\
\bottomrule
\end{tabular}
\end{table}

\begin{thebibliography}{99}
% Existing references retained; added GroupDRO and ICC guidance
\bibitem{guazzi2016} Guazzi, M. et al. 2016 European Guidelines on cardiovascular disease prevention in clinical practice. \textit{Eur. Heart J.} \textbf{37}, 2315-2381 (2016).
\bibitem{wasserman2012} Wasserman, K., Hansen, J. E., Sue, D. Y., Stringer, W. W. \& Whipp, B. J. \textit{Principles of Exercise Testing and Interpretation} 5th edn (Lippincott Williams \& Wilkins, 2012).
\bibitem{beaver1986} Beaver, W. L., Wasserman, K. \& Whipp, B. J. A new method for detecting anaerobic threshold by gas exchange. \textit{J. Appl. Physiol.} \textbf{60}, 2020-2027 (1986).
\bibitem{sue1988} Sue, D. Y., Wasserman, K., Moricca, R. B. \& Casaburi, R. Metabolic acidosis during exercise in patients with chronic obstructive pulmonary disease. \textit{Chest} \textbf{94}, 931-938 (1988).
\bibitem{yeh1983} Yeh, M. P., Gardner, R. M., Adams, T. D., Yanowitz, F. G. \& Crapo, R. O. "Anaerobic threshold": problems of determination and validation. \textit{J. Appl. Physiol.} \textbf{55}, 1178-1186 (1983).
\bibitem{rajkomar2019} Rajkomar, A., Dean, J. \& Kohane, I. Machine learning in medicine. \textit{N. Engl. J. Med.} \textbf{380}, 1347-1358 (2019).
\bibitem{santos2014} Santos-Lozano, A. et al. A new algorithm to estimate anaerobic threshold based on heart rate variability. \textit{Comput. Methods Programs Biomed.} \textbf{114}, 8-14 (2014).
\bibitem{petek2021} Petek, B. J. et al. Machine learning for personalized cardiopulmonary exercise testing. \textit{Curr. Opin. Cardiol.} \textbf{36}, 549-557 (2021).
\bibitem{vaswani2017} Vaswani, A. et al. Attention is all you need. \textit{Adv. Neural Inf. Process. Syst.} \textbf{30}, 5998-6008 (2017).
\bibitem{devlin2018} Devlin, J., Chang, M. W., Lee, K. \& Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. \textit{arXiv preprint} arXiv:1810.04805 (2018).
\bibitem{dosovitskiy2020} Dosovitskiy, A. et al. An image is worth 16x16 words: Transformers for image recognition at scale. \textit{arXiv preprint} arXiv:2010.11929 (2020).
\bibitem{groupdro2020} Sagawa, S., Koh, P. W., Hashimoto, T. B. \& Liang, P. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. \textit{Proc. ICML} (2020).
\bibitem{koo2016} Koo, T. K. \& Li, M. Y. A guideline of selecting and reporting intraclass correlation coefficients for reliability research. \textit{J. Chiropr. Med.} \textbf{15}(2), 155--163 (2016).
\bibitem{ats2003} American Thoracic Society \& American College of Chest Physicians. ATS/ACCP Statement on cardiopulmonary exercise testing. \textit{Am. J. Respir. Crit. Care Med.} \textbf{167}, 211-277 (2003).
\end{thebibliography}

\vfill
\hrule
\footnotesize
\noindent\textit{Manuscript received: [Date]; accepted: [Date]; published online: [Date]} \\
\copyright~2025 The Author(s). This article is licensed under a Creative Commons Attribution 4.0 International License.

\end{document}
\documentclass[11pt, a4paper]{article}

%% ===== PACKAGES =====
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs} % Tables
\usepackage{hyperref} % Hyperlinks
\usepackage{geometry} % Margins
\usepackage{authblk}  % Author block
\usepackage{xcolor}   % Colors
\usepackage{tcolorbox} % Placeholders during drafting
\usepackage{lmodern}  % Modern font

%% === NO PARAGRAPH INDENTATION ===
\usepackage{parskip}

%% ===== DOCUMENT GEOMETRY =====
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

%% ===== HYPERLINK SETUP =====
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdftitle={A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from CPET},
    pdfpagemode=FullScreen,
}

%% ===== TITLE AND AUTHOR INFORMATION =====
\title{\textbf{A Multi-Center, Generalizable Deep Learning Framework for Automated Anaerobic Threshold Assessment from Cardiopulmonary Exercise Tests}\\\vspace{2pt}\large A Diagnostic Accuracy and Reader Study}
\author[1]{WANG Cong}
\author[2]{XU Bei}
\author[1]{MI Shou-ling\thanks{Corresponding author: email@address.com}}

\affil[1]{Zhongshan Hospital, Fudan University, China}
\affil[2]{}

\date{\today}

%% ===== BEGIN DOCUMENT =====
\begin{document}

\maketitle

\begin{tcolorbox}[title={Key Messages},colback=gray!5,colframe=gray!40]
\small
- CPET-former delivers expert-level accuracy for AT and maintains performance at unseen centers (LOCO), enabling standardized interpretation across hospitals and devices.\\
- A large, multi-center, vendor-diverse CPET cohort (harmonized across centers/devices; 69 features, 4 AT targets) supports standardized diagnostic pathways and auditable, scalable clinical practice.\\
- Reader study shows non-inferiority to senior experts and superiority over junior/intermediate readers with perfect reproducibility, facilitating consistent decisions and reduced burden.\\
- Decision utility at clinical thresholds (e.g., 11/14 mL/kg/min) supports risk stratification and perioperative triage.
\end{tcolorbox}

%% Lightweight placeholder for numbers/centers/devices during drafting
\newcommand{\placeholder}[1]{\textcolor{red}{[#1]}}

\begin{abstract}
\noindent\textbf{Background}: The anaerobic threshold (AT) from cardiopulmonary exercise testing (CPET) is a key prognostic marker for risk stratification, perioperative assessment, and rehabilitation. Manual AT determination (e.g., V-slope) is time-consuming, experience-dependent, and exhibits substantial inter- and intra-observer variability, constraining scalability and standardization.

\noindent\textbf{Methods}: We curated CPET-12k, a standardized multi-center dataset of \placeholder{12,000} tests from three hospitals (\placeholder{Zhongshan}, \placeholder{Shanxi}, \placeholder{Xuhui}) and two device vendors (\placeholder{Ganshorn}, \placeholder{Cosmed}). Consensus ground truth was established via a two-reader protocol with blinded adjudication. We developed a transformer-based framework (\textit{CPET-former}) and applied GroupDRO \cite{groupdro2020} for domain generalization. Generalization was assessed via mixed cross-validation and leave-one-center-out (LOCO). We further conducted a blinded reader study with \placeholder{12} clinicians to compare AI against human readers across seniority.

\noindent\textbf{Findings}: CPET-former achieved strong internal accuracy for AT (MAE \placeholder{X}; $R^2$ \placeholder{X}). Under LOCO, GroupDRO improved performance at unseen centers (MAE \placeholder{X} vs. \placeholder{Y}; $p<0.01$). In the reader study, AI matched senior experts (MAE \placeholder{X} vs. \placeholder{Y}; $p=\,$n.s.) and exceeded junior/intermediate readers (MAE \placeholder{Z}; $p<0.001$). Inter-reader reliability was moderate (ICC \placeholder{0.78}), while AI predictions were perfectly reproducible (ICC $=1.00$). A self-supervised variant achieved \placeholder{\textasciitilde95\%} of full-data performance using \placeholder{10\%} labels.

\noindent\textbf{Interpretation}: We present a generalizable, objective, and highly consistent AI framework for automated AT assessment. The model demonstrates robust real-world performance, including at unseen centers, and achieves senior-expert-level accuracy with perfect reproducibility, enabling standardized CPET interpretation and reduced clinical burden.
\end{abstract}

\section{Introduction}

Cardiopulmonary exercise testing (CPET) integrates cardiovascular, pulmonary, and metabolic responses to exertion \cite{guazzi2016}. Among CPET-derived metrics, the anaerobic threshold (AT) is central to prognosis and decision-making in heart failure, perioperative risk, and rehabilitation \cite{wasserman2012, beaver1986}. Conventional AT determination via visual inspection (e.g., V-slope) \cite{sue1988} is subjective and labor-intensive. Inter- and intra-observer agreement can be modest even among experienced clinicians \cite{yeh1983}, compromising reproducibility and constraining scale.

Traditional automated approaches (e.g., curve-fitting) are sensitive to noise and protocol variability and often fail to generalize across vendors and clinical settings. Prior machine learning studies \cite{santos2014, petek2021} are typically single-center and small-scale, with limited validation on unseen centers. Robust generalization and head-to-head comparison with clinicians remain underexplored.

We address this gap with a multi-center, generalizable AI framework for automated AT assessment. Our aims are to deliver: (i) a large, standardized dataset (CPET-12k) spanning three centers and two device vendors; (ii) a transformer-based model (CPET-former) tailored to CPET time-series; (iii) domain generalization via GroupDRO to improve worst-center performance; and (iv) a blinded reader study benchmarking AI against clinicians. Our hypothesis is that AI accuracy and consistency are non-inferior to senior experts.

\section{Methods}

\subsection{Study Design and Ethics}
We conducted a multi-center, retrospective diagnostic accuracy study and a prospective-simulated blinded reader study. Institutional review board approvals were obtained at \placeholder{Zhongshan}, \placeholder{Shanxi}, and \placeholder{Xuhui} with consent waived.

\subsection{Dataset and Standardization (CPET-12k)}
CPET-12k comprises 12{,}829 ramp-protocol examinations from three hospitals (\textit{shanxi}, \textit{xuhui}, \textit{zhongshan}) and two vendors (Ganshorn, COSMED). Adults (\placeholder{$>$18} years) who completed maximal or symptom-limited CPET with acceptable quality per ATS/ACCP \cite{ats2003} were included; we excluded incomplete files, protocol deviations, and technical artifacts.

\textbf{Acquisition pipeline.} Raw vendor spreadsheets are converted to a unified CPET standard (v1.4) using a CLI (\texttt{cpetx-data extract}). Vendor-specific extractors (COSMED, Ganshorn) are driven by YAML mappings against a common schema. Device columns and summary cells are mapped to standard names/units then written to per-center HDF5 files named \texttt{cpet\_data\_source\_<center>.h5}. For this study, the immutable source HDF5 files are:
\begin{itemize}
  \item \path{/home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_shanxi.h5}
  \item \path{/home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_zhongshan.h5}
  \item \path{/home/cheng/workspace/vox_cpet/data/cpet/source/cpet_data_source_xuhui.h5}
\end{itemize}
These files are direct extracts from the original CPET exports using the CPET standard; beyond field naming/unit unification, no cleaning, interpolation, resampling, or feature engineering is applied at this stage.

\textbf{Standardization layer.} The CPET schema enumerates breath-by-breath fields, summary targets, and metadata types. Mappings apply unit conversions and normalization rules, for example: liters to mL/min for VO\textsubscript{2}/VCO\textsubscript{2} (Ganshorn), hPa to mmHg for barometric pressure, categorical encoding for gender, normalization of date/time strings, and mapping of phase markers to \texttt{Load\_Phase}. COSMED/Ganshorn adapters are specified in YAML and versioned with the schema for traceable harmonization (paths: \path{/root/autodl-tmp/vox_cpet/cpetformat/cpet.yaml}, \path{cosmed.yaml}, \path{ganshorn.yaml}).

\textbf{Cleaning and preprocessing.} From the per-center HDF5 sources, we construct an analysis-ready dataset via: (i) 10-second aggregation of breath-by-breath signals where applicable; (ii) per-examination linear interpolation with forward/backward fill for numeric channels; (iii) feature standardization using statistics fitted on the training split; and (iv) explicit feature/target extraction for AT-related endpoints (e.g., \texttt{VO2\_kg\_at\_AT}, \texttt{HR\_at\_AT}, \texttt{Time\_at\_AT}). The resulting processed dataset is stored at \path{/home/cheng/workspace/cpetx_workspace/cpet_former/artifacts/dataset/cpet_dataset.h5}. These steps are deterministic given the same inputs and seeds.

\textbf{Dataset generation and splits.} Processed center-wise frames are mixed into HDF5 datasets using \texttt{cpetx-data generate}. We support: (a) \textit{standard} splits that stratify examinations into train/val/test; (b) explicit center splits where train/val centers and a held-out test center are provided; and (c) leave-one-center-out (LOCO), producing one dataset per held-out center. Standardization uses a scaler fitted on the training split for user-specified feature columns and applied to val/test; scaler parameters (mean/scale) and the list of standardized features are stored in split metadata for inversion and audit.

\textbf{On-disk layout.} Final datasets contain two top-level groups: \texttt{metadata} and \texttt{splits}. The \texttt{metadata} group lists column categories (feature/target/metadata), split statistics (per split and per center), examination-to-center mapping, and standardization parameters. The \texttt{splits} group holds \texttt{train}, \texttt{val}, and \texttt{test}, each with columnar \texttt{features} and a \texttt{metadata} subgroup. Features include breath-by-breath signals such as \texttt{VE}, \texttt{VO2}, \texttt{VCO2}, \texttt{RER}, \texttt{HR}, \texttt{Power\_Load}, \texttt{VT}, \texttt{Bf}, and derived ratios (total \placeholder{69} channels). Targets include \texttt{VO2\_kg\_at\_AT}, \texttt{HR\_at\_AT}, \texttt{Time\_at\_AT}, and \texttt{RER\_at\_AT}. Representative split sizes (examinations): train 10{,}262; val 1{,}282; test 1{,}285 (total 12{,}829). Under LOCO, we release three folds with held-out \textit{shanxi} (8{,}785), \textit{xuhui} (2{,}411), and \textit{zhongshan} (1{,}633).

\textbf{Releases.} We provide the full mixed dataset and derived variants: 10\% subsamples for ablations (\texttt{*\_small}), self-supervised pretraining (\texttt{*\_ssl}), explicit train/val center splits with an external test set (\texttt{*\_explicit\_split}), and LOCO folds (\texttt{*\_loco}).

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{figures/fig_data_organization}
\caption{Data packaging and split structure for CPET-12k.}
\label{fig:data_org}
\end{figure}

\subsection{Reference Standard (Expert Consensus)}
Ground truth AT was defined by a two-reader consensus process. Each case was independently annotated using V-slope corroborated by VE/VCO\textsubscript{2} nadir and ventilatory equivalents. Disagreements were resolved by blinded adjudication. Outlier and quality-control checks enforced physiological plausibility and protocol consistency.

\subsection{Model: CPET-former}
We evaluated a family of models for predicting the anaerobic threshold (AT) with VO\textsubscript{2}@AT as the primary endpoint, and optionally auxiliary targets (e.g., Time@AT, HR@AT).

\textbf{Classical ML baselines.} We include Ridge, SVR, Random Forest, and LightGBM. Time-series are summarized into tabular features (statistical moments, temporal trends/slopes, domain features such as peaks/threshold crossings) together with demographics, and regressed to VO\textsubscript{2}@AT. These serve as point-of-reference comparators.

\textbf{Baseline (cpet\_former).} A transformer encoder over breath-by-breath sequences with sinusoidal positional encoding and multi-head self-attention. The backbone projects input channels (e.g., VE, VO\textsubscript{2}, VCO\textsubscript{2}, RER, HR, Power\_Load, VT, Bf, time) to \texttt{d\_model}, stacks $L$ encoder blocks, and aggregates token features by masked mean pooling. A regression head outputs VO\textsubscript{2}@AT (and optionally Time@AT via an auxiliary head/loss). This is our empirical risk minimization (ERM) baseline on mixed-center data.

\textbf{Center-aware FiLM (cpet\_former\_center\_film).} To improve robustness on known centers, we inject centre embeddings via Feature-wise Linear Modulation: a learned centre vector adds a shallow bias before the encoder and generates per-layer scale/shift (FiLM) to modulate token features. This targets improved performance on the three-center mixed dataset without sacrificing overall accuracy.

\textbf{GroupDRO variant (cpet\_former\_v1).} To improve worst-centre performance under leave-one-center-out (LOCO), we adopt GroupDRO with centres as groups. Training uses per-sample MSE aggregated by a group-weighted objective with momentum-updated group losses and temperature-controlled softmax weighting, emphasizing the currently underperforming centre.

\textbf{Self-supervised pretraining (cpet\_former\_v2).} We pretrain the transformer backbone on unlabeled sequences via masked reconstruction (optionally with a contrastive projection head), then fine-tune a lightweight prediction head with few-shot labels. Backbones can be frozen or partially unfrozen during fine-tuning; pretrained weights are exportable/importable for reproducibility. This aims to retain strong accuracy with 5–10\% labeled data in both mixed-CV and LOCO.

\textbf{Multi-target variant.} A multi-output head (shared backbone) predicts multiple CPET endpoints jointly, e.g., VO\textsubscript{2}@AT, Time@AT, HR@AT, demonstrating that the architecture generalizes across related tasks. The trainer supports weighted auxiliary losses and head-wise diagnostics.

\subsection{Training and Domain Generalization}
Supervision uses MSE on VO\textsubscript{2}@AT as the primary loss; when enabled, Time@AT and HR@AT receive auxiliary losses with fixed weights. Optimization uses AdamW with cosine schedule and warmup; regularization includes dropout, segment mixup, and mild time-warp. For domain robustness: (i) \textit{FiLM} conditions the backbone on centre IDs for known-centre training; (ii) \textit{GroupDRO} reweights centre-wise losses to minimize worst-centre risk under distribution shift \cite{groupdro2020}. For \textit{SSL pretraining}, we mask valid timesteps and reconstruct inputs (with optional contrastive alignment between augmented views), then fine-tune the prediction head with frozen or partially unfrozen backbone.

\subsection{Evaluation Protocols}
We performed (i) stratified mixed $k$-fold cross-validation and (ii) leave-one-center-out (LOCO). Metrics included MAE, RMSE, $R^2$, and agreement analyses (Bland–Altman). Statistical testing used paired comparisons with Bonferroni correction. Calibration and failure modes were examined via error versus RER at AT and protocol duration.

\subsection{Blinded Reader Study}
\placeholder{N} cases were sampled to span diverse protocols and demographics. Readers (junior, intermediate, and senior) independently estimated AT using standardized software without access to ground truth or each other's labels.\\
After a washout period, a subset was repeated to evaluate intra-reader reliability. AI predictions were generated once per case without manual tuning. Agreement was quantified via ICC \cite{koo2016} and Bland–Altman.

\subsection{Interpretability and Quality Control}
We probed attention maps around predicted AT and inspected high-error cases for physiologic plausibility. We report representative cases and failure modes to guide clinical integration.

\section{Results}

\subsection{Study Cohort}
The cohort comprised \placeholder{N} patients (age \placeholder{X}\,$\pm$\,\placeholder{Y} years; \placeholder{Z\%} female) across three centers and two devices. Protocols were predominantly ramp \placeholder{(X\%)} with median duration \placeholder{T} minutes.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Study flow diagram placeholder}]
Insert flow chart: screened $\rightarrow$ included $\rightarrow$ analysis sets (train/val/test; LOCO folds).
\end{tcolorbox}
\caption{Study flow and analysis splits.}
\label{fig:flow}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Baseline characteristics by center.}
\label{tab:baseline}
\begin{tabular}{@{}lccc@{}}
\toprule
Characteristic & Shanxi & Xuhui & Zhongshan \\
\midrule
N (female \%) & 8785 (40.5\%) & 2411 (47.5\%) & 1633 (28.0\%) \\
Age (years) & $59.0\,\pm\,10.3$ & $59.0\,\pm\,13.4$ & $50.6\,\pm\,14.4$ \\
Peak VO\textsubscript{2} (mL/kg/min) & $13.9\,\pm\,3.6$ & $19.6\,\pm\,5.1$ & $20.2\,\pm\,5.8$ \\
\bottomrule
\end{tabular}
\end{table}

% Feature set overview (full spec in Supplementary Table S3)
\noindent\textbf{Feature set.} The model consumes a comprehensive panel of ventilation, gas exchange, hemodynamic, and effort signals (e.g., VE, VO\textsubscript{2}, VCO\textsubscript{2}, RER, HR, Power\_Load, VT, Bf), alongside a small set of derived ratios. The full feature list with units and descriptions is provided in Supplementary Table S3.

\subsection{Model Performance and Generalization}
We compared CPET-former variants against Ridge/SVR/RF/LightGBM baselines. Metrics included MAE, RMSE, and $R^2$ with 95\% CIs; agreement was assessed via Bland–Altman and ICC.

Across mixed cross-validation, CPET-former (ERM) outperformed classical ML baselines. Centre-aware FiLM further improved mixed-centre generalization, and on external centers, GroupDRO reduced worst-centre error and narrowed inter-centre variability. Self-supervised pretraining retained \placeholder{\textasciitilde95\%} of full-supervision accuracy with \placeholder{10\%} labels in both settings (Table~\ref{tab:perf}; Figure~\ref{fig:loco}).

\begin{table}[htbp]
\centering
\caption{Model performance in mixed CV and LOCO (mean [95\% CI]).}
\label{tab:perf}
\begin{tabular}{@{}lcccc@{}}
\toprule
Model & Setting & MAE & RMSE & $R^2$ \\
\midrule
Linear/SVR/RF/LightGBM & Pooled hold-out & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (ERM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (FiLM) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (GroupDRO) & Pooled hold-out & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (ERM) & External centers & \placeholder{Y} & \placeholder{Y} & \placeholder{Y} \\
CPET-former (GroupDRO) & External centers & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
CPET-former (SSL few-shot) & Pooled hold-out/LOCO & \placeholder{X} & \placeholder{X} & \placeholder{X} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={External-center generalization placeholder}]
Insert center-wise MAE/RMSE for ERM vs GroupDRO;\\ highlight improvement at worst/unseen center.
\end{tcolorbox}
\caption{Performance on external centers by site.}
\label{fig:loco}
\end{figure}

\subsection{Reader Study: AI vs. Clinicians}
In the blinded reader study (\placeholder{N} cases), AI performance matched senior experts (MAE \placeholder{X} vs. \placeholder{Y}; $p=\,$n.s.) and exceeded junior/intermediate readers (MAE \placeholder{Z}; $p<0.001$). Inter-reader ICC was \placeholder{0.80} (95\% CI \placeholder{0.75--0.84}), whereas AI predictions were perfectly reproducible (ICC $=1.00$).

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Reader study boxplots placeholder}]
Insert boxplots of MAE by reader seniority vs AI.
\end{tcolorbox}
\caption{Reader study accuracy comparison.}
\label{fig:reader}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={Bland–Altman plots placeholder}]
Insert Bland–Altman plots: (a) AI vs. consensus; (b) Senior vs. consensus.
\end{tcolorbox}
\caption{Agreement analyses against expert consensus.}
\label{fig:ba}
\end{figure}

\subsection{Secondary Analyses}
A self-supervised variant (\placeholder{CPET-former-SSL}) achieved \placeholder{\textasciitilde95\%} of full-supervision performance using \placeholder{10\%} labels (Figure~\ref{fig:ssl}); multi-task extensions are reported in the Supplement.

\begin{figure}[htbp]
\centering
\begin{tcolorbox}[colback=gray!10,colframe=gray!50,title={SSL learning curve placeholder}]
Insert learning curve: labeled fraction vs. MAE/$R^2$.
\end{tcolorbox}
\caption{Label efficiency via self-supervision.}
\label{fig:ssl}
\end{figure}

\section{Discussion}

\textbf{Principal findings.} We built a large, standardized multi-center CPET dataset and developed an AI framework that achieves accurate, objective, and reproducible AT assessment. GroupDRO markedly improved generalization to unseen centers under LOCO, addressing a key barrier to clinical adoption. In a blinded reader study, AI achieved senior-expert accuracy and perfect reproducibility, overcoming inherent subjectivity in manual interpretation.

\textbf{Relation to prior work.} Prior AI-CPET studies are typically single-center with limited validation. Transformers capture long-range temporal dependencies \cite{vaswani2017}, aligning with the physiological progression of exercise. GroupDRO \cite{groupdro2020} minimizes worst-group risk, offering principled domain robustness in multi-center settings.

\textbf{Strengths.} (i) Scale and diversity across centers/devices; (ii) rigorous consensus ground truth; (iii) External-center validation approximating real-world practice; (iv) head-to-head comparison with clinicians; (v) interpretability analyses and QC of error cases.

\textbf{Limitations.} Retrospective design; limited number of centers/vendors; lack of real-time (online) validation; demographics predominantly \placeholder{region}. Future work should expand geography and device coverage, evaluate online inference, and examine downstream clinical impact.

\textbf{Clinical implications and future work.} In routine clinical practice (e.g., within reporting systems or device software), this approach can standardize CPET interpretation and reduce workload. Extending to multi-task outputs (e.g., VT1/VT2, peak VO\textsubscript{2}) and adding uncertainty quantification will broaden utility and support safe adoption.

\section{Conclusion}

We present a generalizable AI framework for automated AT assessment that performs at senior-expert level with perfect reproducibility and robust cross-center generalization. This enables standardized, scalable CPET interpretation in diverse clinical environments.

\newpage

% ===== BACKMATTER =====
\section*{Author Contributions}
B.X. conceived the study, designed the model, performed the analyses, and drafted the manuscript. C.W. acquired data, led clinical validation, and revised the manuscript. All authors approved the final manuscript.

\section*{Competing Interests}
B.X. is an employee of BexiMed Co., Ltd. C.W. declares no competing interests.

\section*{Data Availability}
The datasets generated and analyzed during the current study are not publicly available due to patient privacy regulations but are available from the corresponding author upon reasonable request and with appropriate institutional approvals.

\section*{Code Availability}
The CPET-former implementation and analysis scripts will be released upon publication at: \url{https://github.com/org/CPET-former}.

\section*{Supplementary Material}
\noindent\textbf{Supplementary Table S1. CPET Data Specification (overview).} The dataset contains 69 breath-by-breath feature channels grouped as follows: (i) Ventilation and gas exchange: VE, VO\textsubscript{2}, VCO\textsubscript{2}, VO\textsubscript{2}/kg, VE/VO\textsubscript{2}, VE/VCO\textsubscript{2}, VO\textsubscript{2}/HR; (ii) Respiratory timing and mechanics: Bf, VT, Ti, Te, Ttot, Ti/Ttot, VD/VT; (iii) Gas tensions: PetO\textsubscript{2}, PetCO\textsubscript{2}, PaO\textsubscript{2}, PaCO\textsubscript{2}, PaCO\textsubscript{2} (est.); (iv) Workload/protocol: Power\_Load, RPM, Load\_Phase; (v) Energy expenditure/substrate split: METS, EE (kcal/h; kg-normalized; total), CHO/Fat/PRO (kcal/h, kg-normalized, \%). ECG-derived signals include HR, HRR, and ST/S amplitudes across standard leads (I/II/III, aVR/aVL/aVF, V1--V6). Units are harmonized to L/min (VE), mL/min (VO\textsubscript{2}, VCO\textsubscript{2}), mL/kg/min (VO\textsubscript{2}/kg), bpm (HR), breaths/min (Bf), L (VT), W (Power\_Load), and unitless ratios for RER and ventilatory equivalents.

\noindent\textbf{Supplementary Table S2. Targets and metadata.} Targets: VO\textsubscript{2}/kg at AT (mL/kg/min), HR at AT (bpm), Time at AT (s), RER at AT (unitless). Key metadata: Examination\_ID, Subject\_ID, Time (timestamp), Gender, Age (years), Height\_cm, Weight\_kg, Source\_Device (Ganshorn/COSMED), Institute\_Name (Shanxi/Xuhui/Zhongshan).

% Auto-generated feature list table
\begin{table}[htbp]
\centering
\scriptsize
\caption{Full list of 69 feature columns.}
\label{tab:data_spec_full}
\begin{tabular}{@{}p{0.3\linewidth}p{0.3\linewidth}p{0.3\linewidth}@{}}
\toprule
Feature & Feature & Feature \\
\midrule
 Load\_Phase & BP\_Syst & ST\_II \\
 Bf & BP\_Diast & ST\_III \\
 BR\_pct & HRR & ST\_aVR \\
 VT & CO & ST\_aVL \\
 VE & PaO2 & ST\_aVF \\
 Ti & PaCO2 & ST\_V1 \\
 Te & PetO2 & ST\_V2 \\
 Ttot & PetCO2 & ST\_V3 \\
 Ti\_Ttot\_Ratio & Power\_Load & ST\_V4 \\
 VD\_VT\_Ratio & RPM & ST\_V5 \\
 VT\_Ti & EE\_Total\_kcal & ST\_V6 \\
 VO2 & EE\_kcal\_h & S\_I \\
 VO2\_kg & Fat\_kcal\_h & S\_II \\
 VCO2 & CHO\_kcal\_h & S\_III \\
 VCO2\_kg & PRO\_kcal\_h & S\_aVR \\
 RER & EE\_kg\_kcal\_h & S\_aVL \\
 PaCO2\_est & Fat\_kg\_kcal\_h & S\_aVF \\
 VE\_VO2 & CHO\_kg\_kcal\_h & S\_V1 \\
 VE\_VCO2 & PRO\_kg\_kcal\_h & S\_V2 \\
 METS & Fat\_pct & S\_V3 \\
 HR & CHO\_pct & S\_V4 \\
 VO2\_HR & PRO\_pct & S\_V5 \\
 SpO2 & ST\_I & S\_V6 \\
\bottomrule
\end{tabular}
\end{table}

\begin{thebibliography}{99}
% Existing references retained; added GroupDRO and ICC guidance
\bibitem{guazzi2016} Guazzi, M. et al. 2016 European Guidelines on cardiovascular disease prevention in clinical practice. \textit{Eur. Heart J.} \textbf{37}, 2315-2381 (2016).
\bibitem{wasserman2012} Wasserman, K., Hansen, J. E., Sue, D. Y., Stringer, W. W. \& Whipp, B. J. \textit{Principles of Exercise Testing and Interpretation} 5th edn (Lippincott Williams \& Wilkins, 2012).
\bibitem{beaver1986} Beaver, W. L., Wasserman, K. \& Whipp, B. J. A new method for detecting anaerobic threshold by gas exchange. \textit{J. Appl. Physiol.} \textbf{60}, 2020-2027 (1986).
\bibitem{sue1988} Sue, D. Y., Wasserman, K., Moricca, R. B. \& Casaburi, R. Metabolic acidosis during exercise in patients with chronic obstructive pulmonary disease. \textit{Chest} \textbf{94}, 931-938 (1988).
\bibitem{yeh1983} Yeh, M. P., Gardner, R. M., Adams, T. D., Yanowitz, F. G. \& Crapo, R. O. "Anaerobic threshold": problems of determination and validation. \textit{J. Appl. Physiol.} \textbf{55}, 1178-1186 (1983).
\bibitem{rajkomar2019} Rajkomar, A., Dean, J. \& Kohane, I. Machine learning in medicine. \textit{N. Engl. J. Med.} \textbf{380}, 1347-1358 (2019).
\bibitem{santos2014} Santos-Lozano, A. et al. A new algorithm to estimate anaerobic threshold based on heart rate variability. \textit{Comput. Methods Programs Biomed.} \textbf{114}, 8-14 (2014).
\bibitem{petek2021} Petek, B. J. et al. Machine learning for personalized cardiopulmonary exercise testing. \textit{Curr. Opin. Cardiol.} \textbf{36}, 549-557 (2021).
\bibitem{vaswani2017} Vaswani, A. et al. Attention is all you need. \textit{Adv. Neural Inf. Process. Syst.} \textbf{30}, 5998-6008 (2017).
\bibitem{devlin2018} Devlin, J., Chang, M. W., Lee, K. \& Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. \textit{arXiv preprint} arXiv:1810.04805 (2018).
\bibitem{dosovitskiy2020} Dosovitskiy, A. et al. An image is worth 16x16 words: Transformers for image recognition at scale. \textit{arXiv preprint} arXiv:2010.11929 (2020).
\bibitem{groupdro2020} Sagawa, S., Koh, P. W., Hashimoto, T. B. \& Liang, P. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. \textit{Proc. ICML} (2020).
\bibitem{koo2016} Koo, T. K. \& Li, M. Y. A guideline of selecting and reporting intraclass correlation coefficients for reliability research. \textit{J. Chiropr. Med.} \textbf{15}(2), 155--163 (2016).
\bibitem{ats2003} American Thoracic Society \& American College of Chest Physicians. ATS/ACCP Statement on cardiopulmonary exercise testing. \textit{Am. J. Respir. Crit. Care Med.} \textbf{167}, 211-277 (2003).
\end{thebibliography}

\vfill
\hrule
\footnotesize
\noindent\textit{Manuscript received: [Date]; accepted: [Date]; published online: [Date]} \\
\copyright~2025 The Author(s). This article is licensed under a Creative Commons Attribution 4.0 International License.

\end{document}
